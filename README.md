<a name="readme-topo"></a>

<h1 align='center'>
  üßÆ Algoritmo de Classifica√ß√£o LAC
</h1>

<div align='center'>

[![SO][Ubuntu-badge]][Ubuntu-url]
[![IDE][vscode-badge]][vscode-url]
[![Make][make-badge]][make-url]
[![Linguagem][cpp-badge]][cpp-url]

Algoritmos e Estruturas de Dados I <br>
Engenharia de Computa√ß√£o <br>
Prof. Michel Pires da Silva <br>
CEFET-MG Campus V <br>
2024/1  
</div>

<details>
  <summary>
  <b style='font-size: 15px'>
    üìë Sum√°rio
  </b>
  </summary>
  <ol>
    <li><a href="#-introdu√ß√£o">üîç Introdu√ß√£o</a></li>
    <li>
      <a href="#-fundamenta√ß√£o-te√≥rica">üí° Fundamenta√ß√£o Te√≥rica</a>
      <ul>
        <li><a href='#%EF%B8%8F%EF%B8%8F-fase-de-treino'>üèãÔ∏è‚Äç‚ôÇÔ∏è Fase de Treino</a></li>
        <li><a href='#%EF%B8%8F-fase-de-teste'>üèÉ‚Äç‚ôÇÔ∏è Fase de Teste</a></li>
      </ul>
    </li>
    <li>
      <a href="#-objetivos">üéØ Objetivos</a>
      <ul>
        <li><a href='#objetivo-geral'>Objetivo Geral</a></li>
        <li><a href='#objetivos-espec√≠ficos'>Objetivos Espec√≠ficos</a></li>
      </ul>
    </li>
    <li>
      <a href="#-modelagem-de-aplica√ß√£o">üî¨ Modelagem de Aplica√ß√£o</a>
      <ul>
        <li><a href='#-estrutura-de-dados'>Estrutura de Dados</a></li>
        <li><a href='#%EF%B8%8F%EF%B8%8F-otimiza√ß√µes-propostas'>Otimiza√ß√µes Propostas</a></li>
        <ul>
          <li><a href='#quando-realizar-interse√ß√µes'>Quando Realizar Interse√ß√µes</a></li>
          <li><a href='#irrelev√¢ncia-para-classifica√ß√£o'>Irrelev√¢ncia Para Classifica√ß√£o</a></li>
          <li><a href='#uso-do-unordered-set'>Uso do Unordered_set</a></li>
          <li><a href='#diminui√ß√£o-de-cardinalidade'>Diminui√ß√£o de Cardinalidade</a></li>
          <li><a href='#cache-de-interse√ß√µes'>Cache de Interse√ß√µes</a></li>
          <li><a href='#grid-search-para-hiperpar√¢metros'>Grid Search para Hiperpar√¢metros</a></li>
          <li><a href='#multithreading'>Multithreading</a></li>
          <li><a href='#cache-de-similaridade'>Cache de Similaridade</a></li>
          <ul>
            <li><a href='#similaridade'>Similaridade</a></li>
            <li><a href='#threshold'>THRESHOLD</a></li>
            <li><a href='#cache-de-features-com-similaridade'>Cache de Features Com Similaridade</a></li>
          </ul>
        </ul>
      </ul>
    </li>
    <li>
      <a href="#%EF%B8%8F-metodologia">üó≥Ô∏è Metodologia</a>
      <ul>
        <li><a href='#-arquivos'>Arquivos</a></li>
        <li><a href='#-bibliotecas'>Bibliotecas</a></li>
        <li><a href='#defini√ß√µes-e-estruturas-usadas'>Defini√ß√µes e Estruturas Usadas</a></li>
        <li><a href='#-fun√ß√µes-implementadas'>Fun√ß√µes Implementadas</a></li>
      </ul>
    </li>
    <li>
      <a href="#-testes-e-an√°lises-dos-resultados">üìä Testes e An√°lises dos Resultados</a>
    </li>
    <li><a href="#-conclus√£o">üèÅ Conclus√£o</a></li>
    <li>
      <a href="#-come√ßando">üî® Come√ßando</a>
      <ul>
        <li><a href="#pr√©-requisitos">Pr√©-requisitos</a></li>
        <li><a href="#instalando">Instalando</a></li>
      </ul>
    </li>
    <li><a href="#-ambiente-de-compila√ß√£o-e-execu√ß√£o">üß™ Ambiente de Compila√ß√£o e Execu√ß√£o</a></li>
    <li><a href="#-contato">üì® Contato</a></li>
    <li><a href="#referencias">üìö Refer√™ncias</a></li>
  </ol>
</details>

<details> 
  <summary>
    <b style='font-size: 12px'> Abstract </b>
  </summary>
  Utilizando o algoritmo de classifica√ß√£o LAC, este projeto busca estrat√©gias para aprimorar seu desempenho quando aplicado √† classifica√ß√£o do conjunto de dados PokerHand Data-Set. Atrav√©s do uso de conceitos como sistema de caching de informa√ß√µes, otimiza√ß√µes de interse√ß√µes, predetermina√ß√£o de classifica√ß√µes, e tabelas hash LSH, estudamos melhores maneiras e adapta√ß√µes que permitem uma melhor gest√£o e um controle mais eficiente das classifica√ß√µes feitas pelo algoritmo. Dessa forma, ser√£o apresentados aqui os resultados provenientes de testes e estudos realizados para averiguar a efic√°cia da implementa√ß√£o dessas estrat√©gias em conjunto com o algoritmo em quest√£o, bem como outras abordagens adotadas com o objetivo de melhorar a performance em termos de tempo e acur√°cia ao realizar o procedimento. <br><br>
  üîë <b>Keywords:</b> Lac, Classifica√ß√£o, PokerHand Data-Set, Caching, Otimiza√ß√£o, Hash LSH
<br>
</details>

## üîç Introdu√ß√£o

<div align='justify'>

  Este [trabalho][trabalho-url] (Algoritmo de Classifica√ß√£o LAC) foi proposto na disciplina de Algoritmos e Estruturas de Dados I (AEDSI) pelo professor [Michel Pires da Silva][github-prof].

  A partir da base do algoritmo apresentado pelo Prof. Dr. Adriano Veloso em sua tese de doutorado [^1], neste projeto, iremos nos aprofundar em conceitos e pr√°ticas que visam melhorar a efic√°cia de tal algoritmo. O algoritmo apresentado em [^1], utiliza um conceito de treino e teste para classificar determinadas bases de dados. Primeiramente, o algoritmo busca mapear os dados a serem classificados por meio de ocorr√™ncias selecionadas, denominadas base de treino. Em seguida, ao ser apresentada a base de dados onde ser√° feita a classifica√ß√£o, chamada base de teste, o algoritmo, tendo acesso √†s informa√ß√µes coletadas no treino, pode utilizar conceitos como similaridade, confian√ßa e suporte para realizar a classifica√ß√£o de determinado conjunto de dados.

  Neste estudo, iremos aplicar tal algoritmo na classifica√ß√£o do conjunto de dados PokerHand Data-Set [^2]. Este conjunto de dados cont√©m todas as combina√ß√µes poss√≠veis para uma m√£o de cinco cartas no jogo de p√¥quer, bem como a categoria ou classe √† qual essa m√£o pertence. A disposi√ß√£o desse conjunto de dados √© feita da seguinte forma: formam-se 11 colunas para cada m√£o a ser analisada, onde cada coluna representa uma carta ou naipe, de forma que a √∫ltima coluna representa a classe √† qual essa m√£o pertence. Para cada m√£o, uma s√©rie com 11 colunas (10 cartas e 1 classe), as colunas √≠mpares, come√ßando por 1, representam os naipes, enquanto as colunas pares representam as cartas. Os dados s√£o codificados da seguinte forma:

  - ***NAIPES:*** 
    - **1**- Copas, **2**- Espadas, **3**- Ouros, **4**- Paus

 - ***CARTAS:***
    - **1**- √Ås, **2**- Dois, **3**- Tr√™s, **4**- Quatro, **5**- Cinco, **6**- Seis, **7**- Sete, **8**- Oito, **9**- Nove, **10**- Dez, **11**- Valete, **12**- Rainha, **13**- Rei

  - ***CLASSES:***
    - **0**- Nada em m√£os, **1**- Um par, **2**- Dois pares, **3**- Trinca, **4**- Sequ√™ncia, **5**- Flush, **6**- Full House, **7**- Quadra, **8**- Straight Flush, **9**- Royal Flush

  **Exemplo de representa√ß√£o (11D):**
  - **Dados:** 1, 11, 1, 13, 1, 10, 1, 12, 1, 1, 9
  - **Codifica√ß√£o:** Copas-√Ås, Copas-10, Copas-Valete, Copas-Dama, Copas-Rei, Royal Flush

  Dentre todas as classes presentes em nossa base de dados, algumas aparecem com mais frequ√™ncia do que outras. Por exemplo, a probabilidade de um jogador obter uma m√£o Royal Flush √© muito menor do que obter uma m√£o com apenas um par. Sendo assim, a frequ√™ncia de cada classe √© a seguinte. 
  - **0:** Nada em m√£os (49,95202%)  
  - **1:** Um par (42,37905%)
  - **2:** Dois pares (4,82207%)
  - **3:** Trinca (2,05118%)
  - **4:** Sequ√™ncia (0,37185%)
  - **5:** Flush: 54 ocorr√™ncias (0,21591%)
  - **6:** Full House: 36 ocorr√™ncias (0,14394%)
  - **7:** Quadra (0,02399%)
  - **8:** Straight Flush (0,01999%)
  - **9:** Royal Flush (0,01999%)

  Todas as combina√ß√µes de cartas e poss√≠veis m√£os no jogo de p√¥quer totalizam mais de um milh√£o de possibilidades. Para o treinamento de nosso algoritmo, foram selecionados 25 mil exemplos da base de dados original de forma a fornecer informa√ß√µes suficientes para que possamos classificar as demais amostras.

  Dessa forma, empregando a base do algoritmo LAC [^1] para realizar a classifica√ß√£o desta base de dados, iremos buscar meios de otimizar o procedimento de forma a aprimorar a acur√°cia obtida e o tempo gasto para classificar toda a base de dados.

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üí° Fundamenta√ß√£o Te√≥rica

<div align='justify'>

  Neste estudo ser√£o utilizadas apenas as funcionalidades b√°sicas do algoritmo LAC, apesar de sua complexidade adicional devido a v√°rias implementa√ß√µes proposta pelo autor. O conceito base do algoritmo envolve o c√°lculo de vari√°veis como suporte e confian√ßa para determinar a qual classe uma determinada sequ√™ncia de dados pertence. Sendo assim, analisemos como se deu o procedimento base at√© a classifica√ß√£o final.

  ### üèãÔ∏è‚Äç‚ôÇÔ∏è Fase de Treino
  Durante o processo de treinamento, nosso algoritmo mapeia todas as informa√ß√µes fornecidas da seguinte forma: a partir da posi√ß√£o (coluna) em que um dado est√° disposto, √© criado o conceito de tuplas, estruturas do tipo `<Chave, Valor>`, para mape√°-lo. Essas tuplas s√£o formadas a partir do valor da coluna em que o dado se encontra e do valor presente na mesma. Esse processo √© realizado para todas as cartas, deixando de fora as classes de cada linha.

  - **Exemplo de tuplas geradas:**
    - **Dados:** [3, 3, 1, 1, 2, 3, 1]
    - **Mapeamento:** [(1, 3), (2, 3), (3, 1), (4, 1), (5, 2), (6, 3), 1]


  Em conjunto com o mapeamento dos dados, s√£o criadas tabelas invertidas respons√°veis por armazenar as tuplas/features mapeadas e as linhas onde elas ocorrem. Dessa forma, s√£o criadas estruturas `<Chave, Valor>`, onde as chaves s√£o as tuplas/features e o valor √© um array de inteiros contendo todas as linhas onde essa feature ocorre.

  <div align='center'>
    <img src='./images/tabelaFeatures.png' alt='Exemplo de Tabela Invertida de Features' width='300px'>
    <p>Exemplo de Tabela Invertida de Features</p>
  </div>

  De maneira semelhante, √© criada uma tabela invertida respons√°vel por armazenar as classes e as linhas onde elas ocorrem, permitindo o controle sobre a qual classe cada linha do treinamento pertence.

  <div align='center'>
    <img src='./images/tabelaClasses.png' alt='Exemplo de Tabela Invertida de Classes' width='300px'>
    <p>Exemplo de Tabela Invertida de Classes</p>
  </div>

  ### üèÉ‚Äç‚ôÇÔ∏è Fase de Teste
  Ap√≥s realizar o procedimento de treino e ter salvo em mem√≥ria todas as features presentes na base utilizada, bem como as linhas nas quais elas t√™m recorr√™ncias, e de forma semelhante para as classes, nosso algoritmo passa para a fase de teste. Nessa etapa, √© realizada finalmente a classifica√ß√£o de cada linha (m√£o de p√¥quer) presente na base de teste. 

  Para realizar tal procedimento, nosso algoritmo executa as seguintes etapas: Primeiramente, realizamos o mapeamento dos dados de forma semelhante √† fase de treino, gerando tuplas/features, estruturas do tipo `<Chave, Valor>`. Semelhante √† fase de treino, essas features representam as colunas de cada valor e o valor presente em tal posi√ß√£o. 

  <div align='center'>
    <img src='./images/mapeamentoTeste.png' alt='Exemplo de Mapeamento Fase de Teste' width='400px'>
    <p>Exemplo de Mapeamento Fase de Teste</p>
  </div>

  Realizado o mapeamento, acessamos na tabela invertida de features, criada na fase de treino, o array de inteiros que representa cada linha onde determinada feature aparece. Em seguida, realizamos um procedimento que realiza interse√ß√µes entre os arrays provenientes de cada tupla, ou seja, comparamos quais e quantas linhas determinadas tuplas t√™m em comum, de forma a fazer a an√°lise combinat√≥ria de todas as interse√ß√µes poss√≠veis. Durante esse procedimento, ao realizar as interse√ß√µes entre os arrays referentes a cada tupla, calculamos o suporte e a confian√ßa, vari√°veis respons√°veis por classificar cada m√£o. Ao calcular as interse√ß√µes para cada combina√ß√£o de features, iteramos sobre a matriz invertida de classes, criada durante o treinamento, e, para cada classe, fazemos a interse√ß√£o entre o array de inteiros que representa as linhas onde a classe aparece e o array resultante da interse√ß√£o da an√°lise combinat√≥ria das features. O nosso valor **confian√ßa** recebe o tamanho do vetor resultante dessa interse√ß√£o.

  Por fim, na itera√ß√£o para cada classe, para calcular o suporte, dividimos o valor da **confian√ßa** pela quantidade de features presentes na base de dados constru√≠da durante o treinamento. Dessa forma, ao calcular o valor de suporte, este √© somado em um array `resultado`, que √© respons√°vel por guardar a soma do suporte para cada classe. Ap√≥s realizar todas as an√°lises combinat√≥rias poss√≠veis, a classe atribu√≠da para a m√£o ser√° aquela que tiver o maior valor de suporte no array `resultado`.

  Conclu√≠mos, assim, o procedimento necess√°rio para realizar a classifica√ß√£o de cada m√£o/linha da base de dados [^2]. A seguir, veremos as otimiza√ß√µes propostas com o objetivo de aprimorar esse procedimento, buscando alcan√ßar resultados mais satisfat√≥rios em termos de tempo e acur√°cia, bem como a forma com a qual as mesma foram implementadas.

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üéØ Objetivos

<div align="justify">

  ### Objetivo Geral
  O objetivo geral deste estudo √© investigar e aprimorar a efic√°cia do algoritmo Lazy Associative Classifier (LAC) na classifica√ß√£o de uma grande massa de dados, utilizando o PokerHand Data-Set como um caso de estudo [^2]. Busca-se melhorar a precis√£o e efici√™ncia do processo de classifica√ß√£o, explorando otimiza√ß√µes para especificamente a fase de teste do algoritmo, buscando reduzir o tempo de execu√ß√£o e aumentar a acur√°cia das classifica√ß√µes realizadas.

  ### Objetivos Espec√≠ficos
  - Implementar o algoritmo LAC para classificar o PokerHand Data-Set, utilizando a metodologia baseada em suporte e confian√ßa para determinar as classes das m√£os de p√¥quer.
  - Analisar a precis√£o e o desempenho do algoritmo LAC com a implementa√ß√£o padr√£o no conjunto de dados, identificando poss√≠veis limita√ß√µes ou √°reas para melhoria. 
  - Desenvolver e testar t√©cnicas de otimiza√ß√£o que possam reduzir o tempo de execu√ß√£o do algoritmo sem comprometer a acur√°cia da classifica√ß√£o. 
  - Comparar os resultados obtidos ap√≥s a implementa√ß√£o das otimiza√ß√µes com os resultados da implementa√ß√£o padr√£o, avaliando melhorias em termos de efici√™ncia computacional e precis√£o da classifica√ß√£o. 

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üî¨ Modelagem de Aplica√ß√£o 

<div aling='justify'>

  Partindo do conceito apresentado acima, √© poss√≠vel abordar diferentes solu√ß√µes para o nosso estudo. Nesta se√ß√£o, apresentaremos a forma com a qual modelamos o problema, bem como as estrat√©gias de otimiza√ß√£o empregadas para aumentar o desempenho em termos de acur√°cia das classifica√ß√µes e tempo gasto nessa tarefa. Para implementar nossa solu√ß√£o, a linguagem escolhida foi C++, uma vez que esta nos oferece um paradigma procedural que demonstra √≥timo desempenho ao lidar com o processamento de grandes volumes de instru√ß√µes e tamb√©m conta com a vantagem de ter diversas estruturas de dados implementadas que facilitam a modelagem da solu√ß√£o

  ### üìä Estrutura de Dados

  Compreendendo o procedimento proposto pelo algoritmo [^1], torna-se claro que, em alguns casos, estruturas de dados prim√°rias n√£o s√£o suficientes para construir uma solu√ß√£o ideal. Por exemplo, a constru√ß√£o das tabelas invertidas, tanto na fase de treino quanto na de teste. Sendo assim, torna-se mister o uso de estruturas de dados mais complexas, a fim de obter um c√≥digo limpo, que mantenha a consist√™ncia com o modelo apresentado e apresente bom desempenho.

  A come√ßar pelo exemplo citado acima, definamos como e com quais estruturas de dados foram implementadas as tabelas invertidas. Primeiramente, ao mapear as entradas de dados, antes mesmo de come√ßar a preencher as tabelas invertidas de features e classes, utilizou-se da estrutura `pair`, apresentada em [^3]. Essa estrutura nos permite armazenar dois valores em uma √∫nica vari√°vel, estabelecendo de forma clara o conceito de tupla, ideal para modelar esses dados. Fica evidente que os valores 
  armazenados em cada `pair` correspondem ao n√∫mero da coluna e ao valor presente na mesma, sendo, portanto, um `pair` 
  do tipo <int,int>. Essa estrutura foi utilizada ainda em outras partes da aplica√ß√£o, dada sua efic√°cia e facilidade de uso.

  Para a cria√ß√£o das tabelas invertidas, primeiramente referente √†s features, utilizou-se da estrutura `unordered_map`, apresentada em [^4]. Tal estrutura representa uma tabela que, novamente, utiliza-se do conceito <Chave, Valor>. Para modelar nossos dados, definiu-se que a chave para cada `unordered_map` seria uma estrutura do tipo `pair`, citada acima, e o valor contido na mesma seria representado por um `vector`, estrutura apresentada em [^5], uma esp√©cie de array din√¢mico, otimizado, de  f√°cil uso e com pouca necessidade de gerenciamento de mem√≥ria. Nessas tabelas, as estruturas do tipo `pair` representam as features, e as do tipo `vector` representam as linhas onde cada feature teve recorr√™ncia. De forma semelhante, deu-se a implementa√ß√£o da tabela invertida referente √†s classes, sendo que a √∫nica diverg√™ncia se deu ao fato de que as chaves utilizadas para preencher o `unordered_map` foram vari√°veis do tipo inteiro, que por sua vez representam as classes em quest√£o, enquanto seus valores, tamb√©m de forma semelhante, s√£o constitu√≠dos por um `vector` que armazena as linhas onde as mesmas apareceram na base de treino. Passemos, agora, para estruturas utilizadas durante o teste. 

  Como exemplificado no t√≥pico sobre o fundamento te√≥rico, durante o mapeamento de dados realizado na fase de teste, √© necess√°rio utilizar estruturas para modelar as features presentes nesta base de dados, de forma semelhante √†s usadas durante o processo de treino. Para tanto, utilizou-se a mesma estrutura `pair`. Continuando na mesma fase da aplica√ß√£o, utilizou-se novamente a estrutura do tipo `vector` para guardar os resultados das combina√ß√µes feitas entre as features de cada linha. Dessa vez, o valor armazenado foi um outro `vector`, criando-se o conceito de matriz, onde cada linha guardava a combina√ß√£o das features, estruturas do tipo `pair`, que posteriormente seriam utilizadas para fazer as interse√ß√µes e o c√°lculo do suporte e confian√ßa. Por fim, para armazenar os valores provenientes das interse√ß√µes feitas durante o processo de an√°lise combinat√≥ria, foi utilizada, novamente, a estrutura `vector`, uma vez que esta nos possibilita saber a quantidade de elementos armazenados nela de forma nativa, sem a necessidade de implementar nenhuma fun√ß√£o auxiliar.

  √â importante destacar a impossibilidade de utilizar determinadas estruturas de dados, como *chave*, em tabelas hash de forma nativa. Por exemplo, a necessidade de usar a estrutura `pair` como *chave* em uma estrutura `unordered_map` √© um caso espec√≠fico. Como a linguagem n√£o oferece suporte nativo para fun√ß√µes de hash para determinadas estruturas, foi necess√°rio criar fun√ß√µes de *hash* que lidam com essas estruturas, assim como fun√ß√µes de *equals* para validar a igualdade entre duas estruturas do mesmo tipo, a fim de utiliz√°-las como chave em outros contextos. Dessa forma, a limita√ß√£o de n√£o trabalhar de forma nativa pode impactar a performance do nosso algoritmo, embora o benef√≠cio da modelagem proposta supere os poss√≠veis malef√≠cios.

  ### üèãÔ∏è‚Äç‚ôÇÔ∏è Otimiza√ß√µes Propostas 

  Inicialmente, para termos no√ß√£o de quais partes de nosso algoritmo necessitam de mais otimiza√ß√£o, criamos a seguinte divis√£o de tarefas, onde cada parte representa um procedimento realizado. Nota-se que, para esta divis√£o, n√£o foram contabilizados os procedimentos realizados na fase de treino, uma vez que esta n√£o √© contabilizada no tempo de execu√ß√£o. Os procedimentos aqui apresentados dizem respeito apenas √† fun√ß√£o de teste:

  **1¬∫ Procedimento:** Leitura linha a linha do arquivo.

  **2¬∫ Procedimento:** Tokeniza√ß√£o/Mapeamento das informa√ß√µes contidas no arquivo para vari√°veis do tipo `vector`.

  **3¬∫ Procedimento:** An√°lise combinat√≥ria das tuplas/features, seguida da interse√ß√£o entre elas.

  **4¬∫ Procedimento:** C√°lculo de suporte e confian√ßa para a classifica√ß√£o.

  Para o 1¬∫ Procedimento, o custo √© linear, aumentando conforme a quantidade de linhas a serem lidas. Contudo, pode-se afirmar que, para a leitura de cada linha, este procedimento tem um custo constante, encontrando-se j√° em uma faixa de rendimento pr√≥ximo √† ideal. Dessa forma, embora existam poss√≠veis otimiza√ß√µes a serem feitas nesse sentido, elas n√£o impactar√£o de forma crucial a performance de nosso algoritmo.

  Analisando agora o 2¬∫ Procedimento, temos que, de forma semelhante ao 1¬∫ Procedimento, seu custo est√° pr√≥ximo da otimiza√ß√£o, uma vez que o custo para realiz√°-lo √© constante $\Theta(K)$, sendo **K** a quantidade de caracteres presentes em cada linha, que √© onze, no caso do PokerHand Data-set. Conclui-se, ent√£o, que este procedimento tamb√©m n√£o surte efeito significativo para nossa aplica√ß√£o.

  Partindo para o 3¬∫ procedimento, onde se encontram as maiores oportunidades de implementar otimiza√ß√µes. Esse procedimento consiste em realizar a an√°lise combinat√≥ria entre todas as features e, durante esse processo, realizar a interse√ß√£o entre elas. O fato √© que existem diversas formas de implementar tanto a an√°lise combinat√≥ria quanto as interse√ß√µes entre os vetores. Contudo, tais procedimentos exigem um custo computacional significativamente maior em compara√ß√£o com todos os demais procedimentos realizados at√© ent√£o, independente da forma como forem implementados. A t√≠tulo de exemplifica√ß√£o, consideremos uma amostra da base de dados para ilustrar:

  **Dados:** 1, 11, 1, 10, 1, 12, 3, 8, 1, 9, 4

  Para este exemplo, temos um total de 1023 combina√ß√µes poss√≠veis, calculadas pela seguinte somat√≥ria:

</div>

$$
\sum_{k=1}^{10} C(10,k) = 1023
$$

<div align='justify'> 

  Isso significa que ser√° necess√°rio, na forma padr√£o da implementa√ß√£o proposta, realizar 1023 processos de interse√ß√£o entre vetores, sendo que, em alguns casos, se trata de interse√ß√µes entre nove ou mais vetores. Para cada interse√ß√£o entre dois ou mais vetores desordenados, que √© o caso de nossa aplica√ß√£o (uma vez que os vetores representam linhas que s√£o dispostas de maneira n√£o ordenada na tabela de features), o custo computacional √© dado por $\Theta(n_{1} \cdot n_{2} \cdot n_{3} \cdots n_{k})$, onde $n$ √© o tamanho de cada vetor. Com isso, vemos o quanto esse custo pode se tornar elevado √† medida que aumenta a quantidade de elementos a serem intersectados.

  #### Quando Realizar Interse√ß√µes:
  A partir deste ponto, surgem otimiza√ß√µes que podem ter um grande impacto na efici√™ncia do nosso algoritmo. Inicialmente, considerou-se a necessidade de n√£o realizar interse√ß√µes quando a an√°lise combinat√≥ria envolve apenas uma √∫nica feature, uma vez que sua interse√ß√£o ser√° ela mesma. Assim, ao realizar an√°lises combinat√≥rias de forma individual, basta acessar a tabela de features na chave correspondente e retornar as linhas que pertencem a essa feature. Embora essa melhoria pare√ßa insignificante, n√£o havia sido prevista inicialmente no modelo base apresentado na fundamenta√ß√£o te√≥rica, e ela evita processamentos desnecess√°rios. A partir dessa melhoria, define-se o conceito a ser seguido para as pr√≥ximas otimiza√ß√µes: evitar ao m√°ximo realizar interse√ß√µes desnecess√°rias e, se poss√≠vel, eliminar o processo de an√°lise combinat√≥ria.

  #### Irrelev√¢ncia para Classifica√ß√£o
  Para a pr√≥xima otimiza√ß√£o implementada, sua origem se deu ao analisar minuciosamente o procedimento de an√°lise combinat√≥ria. Verificou-se que, para determinado conjunto de *features*, ao realizar a interse√ß√£o entre as mesmas, a dimens√£o do *array* resultante era √≠nfima, de modo que, ao utilizar essa dimens√£o para, posteriormente, calcular a confian√ßa e o suporte para cada classe, obtinha-se um valor tamb√©m √≠nfimo para cada classifica√ß√£o. Em um cen√°rio ideal, onde o tempo n√£o impacta na performance, seria necess√°rio realizar todas as interse√ß√µes, ainda que seu resultado se aproximasse da irrelev√¢ncia para a classifica√ß√£o dos dados. Contudo, n√£o sendo este o cen√°rio proposto, optou-se por interromper o processo de an√°lise ao atingir um determinado est√°gio, onde as interse√ß√µes j√° n√£o tinham impacto consider√°vel nas classifica√ß√µes. Isso ocorre porque, quanto maior o conjunto de *features* analisadas, menor seria o *array* de interse√ß√£o e, consequentemente, menor o impacto nas classifica√ß√µes. Com a implementa√ß√£o dessa regra de gerenciamento, o n√∫mero de interse√ß√µes desnecess√°rias foi drasticamente reduzido, assim como o processamento necess√°rio para realiz√°-las. Observou-se tamb√©m que, conforme previsto, a acur√°cia das classifica√ß√µes n√£o sofreu preju√≠zo relevante, mantendo sua m√©dia anterior, com a √∫nica vantagem de melhorar o tempo gasto para realiz√°-las.

  #### Uso do `unordered set`
  Em um contexto geral, buscando ainda outras formas de otimiza√ß√£o, ao ler a documenta√ß√£o da linguagem utilizada para desenvolver o LAC, viu-se que haviam determinadas estruturas de dados que possuem melhor performance do que as utilizadas na vers√£o inicial de nosso m√©todo. Entre tais estruturas de dados, figura-se principalmente o uso de `unordered set`, apresentado em [^7], no lugar do `vector`, estrutura usada para guardar os valores de recorr√™ncia de linhas tanto na fase de treino quanto durante o teste. Dessa forma, uma vez que o tempo de pesquisa fornecido pela estrutura `unordered set` se faz em tempo constante $\Theta(1)$, enquanto para o `vector` tem-se o custo linear $\Theta(n)$, em uma grande quantidade de pesquisas feitas, como no caso da nossa implementa√ß√£o do LAC, obt√©m-se um grande ganho de performance ao longo da execu√ß√£o at√© que seja realizada toda a classifica√ß√£o da base de dados em quest√£o. Com isso, finalizamos as implementa√ß√µes que buscaram otimizar o LAC enquanto classificava o PokerHand Data-set. Podemos concluir que amplas foram as abordagens de otimiza√ß√£o, variando desde simplifica√ß√µes de processos at√© o estudo da base de dados para buscar melhores resultados, mostrando que diversos s√£o os meios de conseguir melhorar determinados processos e alcan√ßar ganhos em desempenho.

  #### Diminui√ß√£o de Cardinalidade
  Passemos para a pr√≥xima otimiza√ß√£o implementada durante este estudo. Tal implementa√ß√£o foi realizada visando seguir o conceito principal para a otimiza√ß√£o do algoritmo: fazer o m√≠nimo de interse√ß√µes poss√≠veis. Contudo, desta vez, a implementa√ß√£o ocorreu ao analisar os dados que eram submetidos para classifica√ß√£o, suas especificidades e como poder√≠amos us√°-los para melhorar a performance. Dessa forma, pensou-se que, se fosse poss√≠vel diminuir a quantidade de dados a serem processados, sem perder suas caracter√≠sticas, ou seja, sem desfigur√°-los, surtiria em um grande impacto, uma vez que seria necess√°rio realizar menos opera√ß√µes para classificar os mesmos dados. 

  Com isso, atrav√©s de um estudo espec√≠fico para a base PokerHand DataSett, viu-se que seria poss√≠vel diminuir a cardinalidade de cada linha/m√£o da seguinte forma: como cada par de colunas seguidas em nossa base de dados representa o naipe e o valor da carta, seria natural implementar um processo que possa juntar cada par de colunas, a fim de reduzir pela metade a quantidade de dados a serem classificados. Dessa forma, nossa base teria sua representa√ß√£o de 0 a 52, sendo cada valor a combina√ß√£o entre um naipe e um valor, formando, assim, uma carta. Diversas s√£o as formas de implementar processos que fa√ßam essa codifica√ß√£o, contudo, desde que n√£o atribuam valores repetidos para combina√ß√µes diferentes, a forma como ele lida com esse processo n√£o impacta significativamente em nosso algoritmo, embora quanto mais simples for a implementa√ß√£o, melhor ser√° o resultado obtido. A seguir, apresentamos a fun√ß√£o respons√°vel por fazer a codifica√ß√£o de cada par de valores.

  **Algoritmo: Codifica√ß√£o de uma carta de baralho** 
  ```pseudo
  Entrada: naipe, valor
  Sa√≠da: carta

  Fun√ß√£o codifica√ß√£o(naipe, valor):
      carta ‚Üê (naipe - 1) * 13 + (valor - 1)
      Retorne carta
  ``` 
  A fim de economizar tempo e melhorar a performance, tal procedimento foi implementado durante o mapeamento das features, tanto na fase de treino quanto na fase de teste. Dessa forma, esta foi uma otimiza√ß√£o que tamb√©m impactou o 2¬∫ procedimento, n√£o se limitando apenas a ele. A t√≠tulo de exemplo, mostramos como se deu a transforma√ß√£o dos dados para uma determinada s√©rie de cartas:

  **Forma Padr√£o:** 1, 1, 1, 10, 1, 11, 1, 12, 1, 13, 9 

  **Transforma√ß√£o:** 

</div>

<div align='center'>
  (1, 1) ‚Üí 0 <br>
  (1, 10) ‚Üí 9 <br>
  (1, 11) ‚Üí 10 <br>
  (1, 12) ‚Üí 11 <br>
  (1, 13) ‚Üí 12 <br>
  (9) ‚Üí 9 <br>
</div>

<div align='justify'>

  Dessa forma, ao reduzir pela metade os dados a serem utilizados durante o processo de an√°lise combinat√≥ria, a efici√™ncia do nosso algoritmo teve um grande aumento, visto que ser√° necess√°rio realizar apenas 31 combina√ß√µes ao inv√©s de 1023, quantidade necess√°ria para a an√°lise de 10 valores. Essa redu√ß√£o, aplicada a todas as linhas do arquivo de teste, tem um grande impacto em todo o procedimento de classifica√ß√£o, sendo essa uma das principais otimiza√ß√µes implementadas.
 
  #### Cache de Interse√ß√µes
  Seguindo √† risca esse conceito, apresenta-se a primeira grande otimiza√ß√£o em rela√ß√£o ao modelo base apresentado anteriormente. Ao percebermos que, durante o processo de an√°lise combinat√≥ria e interse√ß√£o entre as *features* na fase de teste, muitas interse√ß√µes eram realizadas repetidamente, resultando em um grande tempo de processamento para repetir procedimentos j√° realizados, surgiu uma ideia para otimizar esse processo. Pensou-se, ent√£o, em seguir a ideia de mem√≥ria **cache**, presente na maioria dos computadores modernos, para utilizar uma tabela que armazenaria a classifica√ß√£o feita para an√°lises combinat√≥rias j√° realizadas. Dessa forma, ao encontrar um conjunto de *features* j√° processado anteriormente, nosso algoritmo realizar√° apenas uma busca na tabela de **cache**, economizando o processamento das interse√ß√µes e tamb√©m do c√°lculo de suporte e confian√ßa. Para maximizar a quantidade de informa√ß√µes poss√≠veis na mem√≥ria **cache**, ao realizar a an√°lise de um conjunto de *features* ainda n√£o processado, seu resultado/classifica√ß√£o ser√° salvo em uma tabela, tendo como chave um *array* de *pairs* que representam as *features* da an√°lise. Assim, na pr√≥xima vez que surgir a necessidade de processar o mesmo conjunto de *features*, ser√° feita uma busca na tabela; se tal conjunto j√° for uma chave armazenada, o processo de an√°lise ser√° ignorado, pois j√° se conhece o seu resultado. Para essa abordagem, quanto maior for a quantidade de dados a serem classificados, maior ser√° a utiliza√ß√£o da **mem√≥ria cache** e, consequentemente, maior o ganho de desempenho.

  #### Grid Search para Hiperpar√¢metros
  A partir do conceito implementado, de n√£o realizar o processo de an√°lise combinat√≥ria a partir de um valor m√≠nimo para a dimens√£o do **array** de interse√ß√µes, surgiu a necessidade de um par√¢metro que definisse qual seria o limite ideal. A partir desse ponto, se deu a pr√≥xima implementa√ß√£o que traria resultados de otimiza√ß√£o para o LAC. Usando o conceito apresentado por L. He, Z. Gao, Q. Liu, e Z. Yang em [^6], o m√©todo **Grid Search** √© uma t√©cnica amplamente utilizada no contexto de aprendizado de m√°quinas, buscando ajustar hiperpar√¢metros para melhor desempenho de um modelo. A partir de uma s√©rie exaustiva de testes, o m√©todo retorna o melhor valor encontrado para ser usado em determinado par√¢metro. Dessa forma,  este m√©todo foi aplicado no contexto do LAC, mais especificamente em qual seria o valor m√≠nimo ideal para a dimens√£o do vetor de interse√ß√µes, para que seja relevante continuar realizando o processo de an√°lise combinat√≥ria. Seguindo o conceito apresentado pelo GridSearch, o algoritmo foi executado diversas vezes com valores diferentes para o par√¢metro em quest√£o. Como resultado da implementa√ß√£o desse m√©todo, chegamos a um par√¢metro que apresentou o melhor resultado entre todos os testes realizados, concluindo que a dimens√£o m√≠nima esperada para continuar a an√°lise seria de 10 unidades . Com isso, a implementa√ß√£o j√° feita, ponderando quando seria vi√°vel continuar com o processo de an√°lise combinat√≥ria, teve  um impacto ainda mais significativo, uma vez que obtivemos o par√¢metro melhor ajustado para quando parar esta etapa. Para mais informa√ß√µes, sua implementa√ß√£o est√° dispon√≠vel na branch [`grid-search`][grid-search].

  #### Multithreading
  Uma vez que todos os procedimentos realizados para classifica√ß√£o, mesmo ap√≥s a implementa√ß√£o de todas as otimiza√ß√µes j√° citadas, n√£o s√£o dependentes entre si, podemos implementar multithreading em nosso algoritmo, visando a distribui√ß√£o de tarefas e execu√ß√£o em paralelo. Cada thread pode ser respons√°vel por uma parte espec√≠fica da an√°lise combinat√≥ria e, se necess√°rio, realizar a interse√ß√£o entre as features. No que diz respeito √† an√°lise combinat√≥ria e interse√ß√£o, cada thread pode processar uma parte da an√°lise, permitindo que as tarefas sejam realizadas simultaneamente. A interse√ß√£o dos resultados pode ser feita pelas threads conforme necess√°rio, garantindo que cada segmento da an√°lise seja tratado de forma eficiente.

  √â crucial garantir que cada thread termine sua execu√ß√£o antes que o resultado final seja computado. Problemas de assincronia podem surgir se uma thread terminar sua execu√ß√£o antes de outras, o que pode levar a resultados incorretos ou inconsistentes. Portanto, a sincroniza√ß√£o entre threads √© essencial para evitar condi√ß√µes de corrida e inconsist√™ncias nos resultados, que devem ser gerenciadas cuidadosamente para garantir a integridade dos dados.
  
  Optamos por usar a biblioteca `pthread` em C++ em vez da biblioteca `thread` por v√°rias raz√µes. A pthread oferece maior controle sobre a cria√ß√£o e o gerenciamento de threads, al√©m de fornecer uma gama mais ampla de funcionalidades para sincroniza√ß√£o, como mutexes, sem√°foros e barreiras. Essas ferramentas s√£o essenciais em contextos onde a precis√£o e o controle detalhado das opera√ß√µes de multithreading s√£o cruciais. Al√©m disso, pthread √© uma biblioteca madura e amplamente utilizada, o que a torna uma escolha confi√°vel para aplica√ß√µes de alto desempenho.

  Decidimos usar cinco threads, pois esse n√∫mero apresentou o melhor desempenho nos testes realizados. Ap√≥s experimentarmos com diferentes quantidades de threads, descobrimos que cinco era o n√∫mero ideal, equilibrando a carga de trabalho entre as threads e evitando a sobrecarga de gerenciamento que poderia ocorrer com um n√∫mero maior. Esse ajuste permitiu maximizar a efici√™ncia do processamento paralelo, mantendo o uso de recursos em um n√≠vel √≥timo.

  A implementa√ß√£o de multithreading gerou √≥timos resultados, aumentando significativamente a efici√™ncia e a velocidade do algoritmo ao permitir a execu√ß√£o paralela de tarefas.

  Por fim, para o 4¬∫ Procedimento, a busca por m√©todos que pudessem otimiz√°-lo n√£o obteve tantos resultados quanto para o terceiro procedimento. Como apresentado na se√ß√£o de fundamento te√≥rico, o processo de c√°lculo de suporte e confian√ßa para a classifica√ß√£o de determinada linha/m√£o se d√° apenas realizando c√°lculos matem√°ticos, uma vez que a an√°lise combinat√≥ria e interse√ß√µes j√° foram realizadas. Sendo assim, ainda que a implementa√ß√£o do sistema de **mem√≥ria cache** surtisse impacto tamb√©m nesta fase da aplica√ß√£o, reduzindo a necessidade de realiz√°-lo, n√£o houve outra implementa√ß√£o que pudesse otimiz√°-lo, visto que o custo de realizar c√°lculos matem√°ticos tem pouco impacto durante a execu√ß√£o de nosso algoritmo, uma vez que tais instru√ß√µes possuem custo de execu√ß√£o constante.

  #### Cache de Similaridade
  Atrav√©s da √∫ltima otimiza√ß√£o apresentada, os resultados de tempo de execu√ß√£o e acur√°cia tiveram um grande impacto positivo, possibilitando classificar massas de dados que antes n√£o eram poss√≠veis devido ao seu tamanho. Sendo assim, com o intuito de, ainda trabalhando com o conceito de mem√≥ria cache, obter performances ainda melhores, surgiu a pr√≥xima otimiza√ß√£o, que ser√° uma melhoria do conceito j√° apresentado. Inicialmente, o benef√≠cio que a mem√≥ria cache trazia para o fluxo de execu√ß√£o era a vantagem de n√£o precisar realizar determinadas interse√ß√µes, aproveitando as que j√° foram feitas e armazenadas em cache, evitando processamento desnecess√°rio e ganhando tempo. Contudo, a nova forma de implementar o sistema de cache se deu de maneira diferente, apresentando resultados ainda melhores de tempo e precis√£o durante as classifica√ß√µes.

  Na primeira vers√£o do cache, embora houvesse vantagens ao reutilizar interse√ß√µes j√° realizadas, ainda era necess√°rio realizar uma grande quantidade de interse√ß√µes, dado que o processo de an√°lise combinat√≥ria gera uma quantidade significativa de agrupamentos de features, tornando invi√°vel realizar todas. Assim, buscando reduzir ainda mais a necessidade de realizar interse√ß√µes desnecess√°rias, a nova abordagem visa classificar uma linha de forma completa baseada na sua similaridade com linhas j√° classificadas, sem precisar realizar nenhum processo de an√°lise combinat√≥ria e, portanto, nenhuma interse√ß√£o.

  Embora utilize conceitos diferentes para o reaproveitamento de processamento, a mem√≥ria cache utilizando similaridade de linhas opera de maneira semelhante √† primeira vers√£o, em seu conceito b√°sico. Seguindo o fluxo da aplica√ß√£o, inicialmente n√£o h√° como aproveitar nenhum processamento j√° realizado; por√©m, de maneira semelhante √† primeira vers√£o, quanto mais linhas o algoritmo classificar, maior ser√° o ganho produzido pelo sistema de cache. Uma vez realizada a classifica√ß√£o da primeira linha atrav√©s do conceito base de interse√ß√µes, o resultado da classifica√ß√£o √© armazenado em uma tabela hash; contudo, agora a chave da tabela ser√° um vector de pair, representando as features formadas pela linha classificada, e o valor armazenado ser√° a classe resultante da classifica√ß√£o realizada.

  A partir da segunda linha, antes mesmo de iniciar o procedimento de an√°lise combinat√≥ria, as features geradas atrav√©s do mapeamento passam por um processo de an√°lise de similaridade com as linhas j√° classificadas, que constituem as chaves da tabela de mem√≥ria cache com similaridade. Se houver uma linha j√° mapeada que apresente similaridade suficiente com a linha a ser mapeada, o valor de classifica√ß√£o atribu√≠do √† linha j√° classificada tamb√©m ser√° atribu√≠do √† linha a ser classificada, uma vez que a probabilidade de ambas pertencerem √† mesma classe √© muito grande. A partir dessa l√≥gica, a necessidade de se realizar o processo de an√°lise combinat√≥ria e interse√ß√µes diminui ainda mais, resultando em um grande ganho de desempenho. Conforme s√£o feitas as classifica√ß√µes, seus resultados s√£o armazenados na tabela, de forma que chega um determinado ponto da aplica√ß√£o em que n√£o √© mais necess√°rio processar nenhuma nova linha para classifica√ß√£o, uma vez que s√£o grandes as chances de se ter uma linha com coeficiente de similaridade semelhante ao apresentado.

  ##### Similaridade
  A partir do conceito apresentado, surge a necessidade de se definir qual m√©todo ser√° empregado para determinar a similaridade entre duas linhas, de forma a calcular se ambas s√£o suficientemente 'parecidas' para que compartilhem da mesma classe. Existem diversos meios de realizar tal processo, contudo, ainda que haja m√©todos com desempenho semelhante, a similaridade de cossenos foi a escolhida para essa tarefa. Uma vez que o procedimento para calcular a similaridade entre dois vetores espaciais √© realizado pelo m√©todo de similaridade de cossenos, atrav√©s de uma s√©rie de c√°lculos matem√°ticos, sua efic√°cia √© muito alta, assim como o tempo gasto para realizar tal processo. Este foi o principal aspecto considerado para a utiliza√ß√£o desse m√©todo, pois, uma vez que a similaridade entre duas linhas √© calculada diversas vezes durante a execu√ß√£o, outro m√©todo de c√°lculo de similaridade que exigisse mais processamento acabaria por prejudicar o desempenho do processo. Dessa forma, m√©todos como o c√°lculo de similaridade de Jaccard n√£o foram empregados, dado o tempo necess√°rio para realizar o c√°lculo de similaridade em cada opera√ß√£o. 

  ##### THRESHOLD
  O segundo conceito a ser analisado, para a correta implementa√ß√£o da otimiza√ß√£o apresentada acima, √© o limite necess√°rio de similaridade entre duas linhas, para que a classifica√ß√£o de uma possa ser feita com base na outra. Surge, assim, o conceito de threshold, uma rela√ß√£o m√≠nima de semelhan√ßa. Ao utilizar o m√©todo de similaridade de cossenos, observou-se que, embora apresente bons resultados, ainda h√° casos em que o c√°lculo de similaridade pode gerar ru√≠dos, ou seja, imprecis√µes aleat√≥rias durante o c√°lculo, como, por exemplo, aproximar n√∫meros como 7 e 8 de forma a gerar um valor alto de similaridade, mesmo que tal fato n√£o seja verdadeiro para a base de dados com a qual estamos lidando. Dessa forma, torna-se necess√°ria uma rela√ß√£o de similaridade alta, para que esses ru√≠dos n√£o interfiram no processo e gerem classifica√ß√µes imprecisas. Para que pud√©ssemos escolher um valor ideal para o threshold, foi necess√°rio realizar uma s√©rie de testes, o mesmo que usamos para saber o valor m√≠nimo de interse√ß√µes necess√°rias para continuar a an√°lise combinat√≥ria, o Grid Search. A partir desses testes, chegamos a um valor de 0.8, que apresentou os melhores resultados para a base de dados com a qual estamos lidando, garantindo que a semelhan√ßa entre duas linhas seja suficientemente alta para que sejam agrupadas na mesma classifica√ß√£o. Esta implementa√ß√£o do Grid Search para o threshold est√° dispon√≠vel na mesma branch do Grid Search, [`grid-search`][grid-search].

  ##### Cache de Features Com Similaridade
  A otimiza√ß√£o referente ao cache de similaridade entre as linhas surtiu uma grande melhoria no desempenho do algoritmo, uma vez que a necessidade de realizar interse√ß√µes ‚Äî processo que possui maior custo computacional ‚Äî diminuiu drasticamente. Com isso, foi poss√≠vel seguir para a pr√≥xima implementa√ß√£o. Atrav√©s do conceito inicial de cache de features, com o intuito de reaproveitar o processamento de features j√° realizado, surgiu a ideia de aplicar esse mesmo conceito somado ao c√°lculo de similaridade entre as features presentes no cache, garantindo melhor aproveitamento dos c√°lculos j√° efetuados.

  Uma vez iniciado o processo de an√°lise combinat√≥ria, ap√≥s verificar se existe alguma chave presente no cache de interse√ß√µes que corresponda √† que ser√° processada, caso n√£o exista, nosso algoritmo, ao inv√©s de partir diretamente para a realiza√ß√£o de interse√ß√µes entre as features, busca primeiramente se h√° alguma chave no cache que possua a similaridade desejada com a nova linha de features a ser analisada. A similaridade, assim como no modelo apresentado anteriormente, √© calculada a partir do m√©todo de similaridade de cossenos.

  No contexto em que j√° exista uma chave suficientemente similar, o valor dessa chave ‚Äî que corresponde ao suporte atribu√≠do a cada classe ao processar esse conjunto de features ‚Äî ser√° novamente atribu√≠do √†s classes, pois, dado que a similaridade entre os dois conjuntos de features √© not√°vel, √© grande a possibilidade de que ambos resultem na mesma classifica√ß√£o.

  O resultado dessa implementa√ß√£o, como j√° mencionado, foi um uso ainda mais eficiente dos c√°lculos realizados em features anteriores. Com isso, o desempenho do algoritmo durante as classifica√ß√µes foi ainda mais aprimorado, uma vez que o processo de an√°lise combinat√≥ria e de interse√ß√µes foi otimizado, sendo executado por completo apenas quando n√£o h√° nenhum c√°lculo previamente realizado que possa ser reutilizado.

</div>

## üó≥Ô∏è Metodologia

<div align="justify">

  As abordagens propostas para otimizar o algoritmo LAC foram implementadas em C++, utilizando a IDE Visual Studio Code para o desenvolvimento do c√≥digo-fonte. O projeto foi organizado em um diret√≥rio principal, contendo subdiret√≥rios para armazenar os arquivos de c√≥digo-fonte, os datasets utilizados e os arquivos de sa√≠da. A implementa√ß√£o do algoritmo LAC foi dividida em duas etapas principais: a fase de treinamento e a fase de teste. Durante a fase de treinamento, o algoritmo mapeia todas as informa√ß√µes fornecidas e cria tabelas invertidas para armazenar as features e as classes presentes na base de treinamento. Na fase de teste, o algoritmo classifica as m√£os de p√¥quer presentes na base de teste, utilizando a metodologia baseada em suporte e confian√ßa para determinar as classes das m√£os de p√¥quer.

  ### üìÅ Arquivos 

  Para a implementa√ß√£o do algoritmo LAC, o projeto foi organizado em um diret√≥rio principal, contendo subdiret√≥rios para armazenar os arquivos de c√≥digo-fonte, os datasets utilizados e os arquivos de sa√≠da. A seguir, s√£o apresentados os arquivos e diret√≥rios utilizados no projeto:

  - [`datasets/`](datasets): diret√≥rio contendo os datasets utilizados para treinamento e teste do algoritmo LAC.
    - [`poker-hand-training.data`](datasets/poker-hand-training.data): arquivo contendo os dados utilizados para treinar o algoritmo LAC, sendo a base de treinamento do PokerHand Data-Set do UCI Machine Learning Repository [^2].
    - [`poker-hand-testing.data`](datasets/poker-hand-testing.data): arquivo contendo os dados utilizados para testar o algoritmo LAC, sendo a base de teste do PokerHand Data-Set do UCI Machine Learning Repository [^2].
    - [`base-avaliacao/poker-hand-training.data`](datasets/base-avaliacao/poker-hand-training.data): arquivo contendo os dados utilizados para treinar o algoritmo LAC, sendo a base de treinamento do PokerHand Data-Set modificada pelo professor [Michel][github-prof].
    - [`base-avaliacao/poker-hand-testing.data`](datasets/base-avaliacao/poker-hand-testing.data): arquivo contendo os dados utilizados para testar o algoritmo LAC, sendo a base de teste do PokerHand Data-Set modificada pelo professor [Michel][github-prof].
    - [`output.txt`](datasets/output.txt): arquivo de sa√≠da contendo os resultados da classifica√ß√£o das m√£os de p√¥quer.

  - [`images/`](images): diret√≥rio contendo as imagens utilizadas na documenta√ß√£o do projeto.
    - [`tabelaFeatures.png`](images/tabelaFeatures.png): imagem ilustrando um exemplo de tabela invertida de features.
    - [`tabelaClasses.png`](images/tabelaClasses.png): imagem ilustrando um exemplo de tabela invertida de classes.
    - [`mapeamentoTeste.png`](images/mapeamentoTeste.png): imagem ilustrando um exemplo de mapeamento na fase de teste.
    - [`cossenoComReducao.jpeg`](images/cossenoComReducao.jpeg): imagem ilustrando o c√°lculo de similaridade de cossenos com redu√ß√£o de dimensionalidade.
    - [`cossenoSemReducao.jpeg`](images/cossenoSemReducao.jpeg): imagem ilustrando o c√°lculo de similaridade de cossenos sem redu√ß√£o de dimensionalidade.
    - [`reducaoCardinalidade.jpeg`](images/reducaoCardinalidade.jpeg): imagem ilustrando a redu√ß√£o da cardinalidade das features.

  - [`src/`](src): diret√≥rio contendo os arquivos de c√≥digo-fonte do projeto.
    - [`main.cpp`](src/main.cpp): arquivo contendo a fun√ß√£o principal do programa, respons√°vel por realizar a classifica√ß√£o das m√£os de p√¥quer.
    - [`lac.cpp`](src/lac.cpp): arquivo contendo a implementa√ß√£o das fun√ß√µes do algoritmo LAC.
    - [`lac.hpp`](src/lac.hpp): arquivo contendo a defini√ß√£o das fun√ß√µes do algoritmo LAC.

  - [`.gitignore`](.gitignore): arquivo contendo a lista de arquivos e diret√≥rios a serem ignorados pelo Git.
  - [`make.sh`](make.sh): arquivo de script para compilar o c√≥digo-fonte do projeto.
  - [`makefile`](makefile): arquivo contendo as regras para compilar o c√≥digo-fonte do projeto.
  - [`README.md`](README.md): arquivo contendo a documenta√ß√£o do projeto.

  De uma forma compacta e organizada, os arquivos e diret√≥rios est√£o dispostos da seguinte forma:

  ```.
  |
  ‚îú‚îÄ‚îÄ datasets
  |   |   ‚îú‚îÄ‚îÄ base-avaliacao
  ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ poker-hand-testing.data
  ‚îÇ   ‚îÇ   |   ‚îî‚îÄ‚îÄ poker-hand-training.data
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ poker-hand-testing.data
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ poker-hand-training.data
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ output.txt
  ‚îú‚îÄ‚îÄ images
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tabelaFeatures.png
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tabelaClasses.png
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mapeamentoTeste.png
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cossenoComReducao.jpeg
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cossenoSemReducao.jpeg
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reducaoCardinalidade.jpeg
  ‚îú‚îÄ‚îÄ src
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.cpp
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lac.cpp
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lac.hpp
  ‚îú‚îÄ‚îÄ .gitignore
  ‚îú‚îÄ‚îÄ make.sh
  ‚îú‚îÄ‚îÄ makefile
  ‚îî‚îÄ‚îÄ README.md
  ```
  
</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

### üìö Bibliotecas

<div align="justify">

  As bibliotecas utilizadas na implementa√ß√£o do algoritmo LAC s√£o as seguintes:

  - [`lac.hpp`](src/lac.hpp): biblioteca criada pelos autores do projeto, contendo a defini√ß√£o das fun√ß√µes do algoritmo LAC.
  - [`bits/stdc++.h`](https://www.geeksforgeeks.org/bitsstdc-h-c-include/): biblioteca que inclui todas as bibliotecas padr√£o da linguagem C++. Veja abaixo as bibliotecas que usamos da `bits/stdc++.h`:
    - [`iostream`](https://www.cplusplus.com/reference/iostream/): biblioteca padr√£o de entrada e sa√≠da de dados.
    - [`fstream`](https://www.cplusplus.com/reference/fstream/): biblioteca para manipula√ß√£o de arquivos. 
    - [`string`](https://www.cplusplus.com/reference/string/): biblioteca para manipula√ß√£o de strings.
    - [`cmath`](https://www.cplusplus.com/reference/cmath/): biblioteca para fun√ß√µes matem√°ticas.
    - [`vector`](https://www.cplusplus.com/reference/vector/): biblioteca para manipula√ß√£o de vetores.
    - [`unordered_map`](https://www.cplusplus.com/reference/unordered_map/): biblioteca para manipula√ß√£o de tabelas hash.
    - [`unordered_set`](https://www.cplusplus.com/reference/unordered_set/): biblioteca para manipula√ß√£o de conjuntos hash.
    - [`pthread.h`](https://pubs.opengroup.org/onlinepubs/7908799/xsh/pthread.h.html): biblioteca para programa√ß√£o paralela.
  
</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

### Defini√ß√µes e Estruturas Usadas

<div align="justify">

  No arquivo [`lac.hpp`](src/lac.hpp), s√£o definidas as estruturas de dados utilizadas no algoritmo LAC, bem como algumas vari√°veis globais. A seguir, s√£o apresentadas as defini√ß√µes e estruturas utilizadas:

  - **`#define MIN_SUPPORT 0`**: defini√ß√£o do suporte m√≠nimo para a classifica√ß√£o de uma linha.

  - **`#define DECREASE_CARDINALITY 1`**: defini√ß√£o para reduzir a cardinalidade das features.

  - **`#define USE_COSINE_SIMILARITY 1`**: defini√ß√£o para usar a similaridade de cossenos.

  - **`#define THRESHOLD 0.8`**: defini√ß√£o da confian√ßa m√≠nima para a classifica√ß√£o de uma linha.

  - **`#define MAX_COMBS 3`**: defini√ß√£o do n√∫mero m√°ximo de combina√ß√µes de features a serem analisadas.

  - **`using namespace std`**: defini√ß√£o do namespace padr√£o da linguagem C++.

  - **`struct pairHashSimilarity`**: Essa estrutura define uma fun√ß√£o hash para um par (`std::pair`). A fun√ß√£o hash √© uma implementa√ß√£o personalizada que combina os valores hash dos dois elementos do par usando a opera√ß√£o XOR (`^`).
    - `hash<T1>{}(p.first)`: Calcula o valor hash do primeiro elemento do par.
    - `hash<T2>{}(p.second)`: Calcula o valor hash do segundo elemento do par.
    - `hash1 ^ hash2`: Combina os dois valores hash usando XOR.

  - **`template <typename T> void hashCombine(size_t& seed, T const& v)`**: Essa √© uma fun√ß√£o auxiliar para combinar de forma mais robusta um valor hash existente (`seed`) com um novo valor (`v`), utilizando uma f√≥rmula que inclui deslocamento de bits e uma constante m√°gica (`0x9e3779b9`), que ajuda a espalhar os bits de forma mais uniforme.
    - `seed ^= hash<T>()(v)`: Combina o valor hash de v com o seed existente usando XOR.
    - `0x9e3779b9`: Constante usada para espalhar bits de forma uniforme, derivada da propor√ß√£o √°urea.
    - (`seed << 6`) e (`seed >> 2`): Opera√ß√µes de deslocamento de bits que ajudam a misturar os bits do seed.

  - **`struct pairHash`**: Essa estrutura define uma fun√ß√£o hash para um par (`std::pair`) usando a fun√ß√£o hashCombine, que combina de maneira mais robusta os hashes dos dois elementos do par.
    - `retval = hash<T>()(rhs.first)`: Calcula o valor hash do primeiro elemento e o armazena em retval.
    - `hashCombine(retval, rhs.second)`: Combina retval com o hash do segundo elemento usando hashCombine.
    - `return retval`: Retorna o valor hash combinado.

  - **`struct vectorPairHash`**: Essa estrutura define uma fun√ß√£o hash para um `vector` de pares de inteiros, utilizando `pairHash` para calcular os hashes dos elementos no vetor e combin√°-los.
    - `pairHash{}(p)`: Calcula o hash de cada par no vetor
    - `seed ^= ...`: Combina o hash de cada par com o `seed` existente usando XOR e uma constante m√°gica.
    - `return seed`: Retorna o hash final para o vetor.

  - **`struct vectorPairEqual`**: Essa estrutura define uma fun√ß√£o de igualdade para `vector` de pares de inteiros. Ela compara dois vetores para ver se eles s√£o iguais.
    - `return lhs == rhs`: Retorna verdadeiro se os dois vetores forem iguais, falso caso contr√°rio.

  - **`using cacheKey = unordered_set<pair<int, int>, pairHashSimilarity>`**: Essa linha define um `typedef` ou `using` para `unordered_set` de pares de inteiros com a fun√ß√£o hash `pairHashSimilarity`.

  - **`using cacheValue = int`**: Essa linha define um `typedef` ou `using` para um inteiro, que ser√° o valor armazenado na tabela de cache.

  - **`struct ThreadData`**: Essa estrutura define os dados que ser√£o passados para cada thread durante a execu√ß√£o paralela do algoritmo LAC.
    - `vector<unordered_set<pair<int, int>, pairHash>>* combinationsFeatures`: Ponteiro para o vetor de combina√ß√µes de features.
    - `unordered_map<pair<int, int>, unordered_set<int>, pairHash>* features`: Ponteiro para a tabela de features.
    - `unordered_map<int, unordered_set<int>>* classes`: Ponteiro para a tabela de classes.
    - `unordered_map<cacheKey, cacheValue, vectorPairHash, vectorPairEqual>* similarityCache`: Ponteiro para a tabela de cache de similaridade.
    - `bool* shouldStop`: Ponteiro para a vari√°vel que indica se o processo de an√°lise deve ser interrompido.
    - `int start`: √çndice de in√≠cio do intervalo de combina√ß√µes.
    - `int end`: √çndice de fim do intervalo de combina√ß√µes.
    - `double* result`: Ponteiro para a vari√°vel que armazena o resultado da classifica√ß√£o.

  - **`class Lac`**: Essa classe define o algoritmo LAC, onde as fun√ß√µes s√£o separadas em `private`e `public`:
    - `private`:
      - `unordered_map<pair<int, int>, unordered_set<int>, pairHash> features`: Tabela de features.
      - `unordered_map<int, unordered_set<int>> classes`: Tabela de classes.

    - `public`:
      - `Lac(unordered_map<pair<int, int>, unordered_set<int>, pairHash> features, unordered_map<int, unordered_set<int>> classes)`: Construtor da classe Lac.
      - `void training(string path)`: Fun√ß√£o de treinamento do algoritmo LAC.
      - `float testing(string path)`: Fun√ß√£o de teste do algoritmo LAC.
      - `static unordered_set<int> intersectionAll(vector<unordered_set<int>> list)`: Fun√ß√£o para calcular a interse√ß√£o de todos os conjuntos em uma lista.
      - `int findMaxIndex(double* arr, int size)`: Fun√ß√£o para encontrar o √≠ndice do maior valor em um array.
      - `vector<int> splitString(string line)`: Fun√ß√£o para dividir uma string em um vetor de inteiros.
      - `vector<unordered_set<pair<int, int>, pairHash>> combinations(const vector<pair<int, int>>& c, int k)`: Fun√ß√£o para gerar todas as combina√ß√µes de tamanho k de um vetor de pares de inteiros.
      - `void populateCache(cacheKey lineFeatures, cacheValue classesSupport)`: Fun√ß√£o para popular a cache de similaridade.
      - `static pair<vector<double>, double> checkSimilarity(cacheKey lineFeatures)`: Fun√ß√£o para verificar a similaridade entre duas linhas.
      - `static double cosineSimilarity(const vector<pair<int, int>>& set1, const vector<pair<int, int>>& set2)`: Fun√ß√£o para calcular a similaridade de cossenos entre dois vetores.
      - `static void* threadIntersection(void* arg)`: Fun√ß√£o para realizar a interse√ß√£o em paralelo.
      - `static int INTERSECTION_LIMIT`: Limite de interse√ß√£o.
      - `static unordered_map<cacheKey, cacheValue, vectorPairHash, vectorPairEqual> similarityCache`: Tabela de cache de similaridade.
      - `static pthread_mutex_t mutex`: Mutex para sincroniza√ß√£o entre threads.

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

### üìù Fun√ß√µes Implementadas

<div align="justify">

  A seguir, s√£o apresentadas as fun√ß√µes implementadas no algoritmo LAC, bem como a descri√ß√£o de suas funcionalidades:

  #### [**`int main()`**](src/main.cpp)
  Esta fun√ß√£o √© respons√°vel por apenas fazer o gereciamento do fluxo de execu√ß√£o do programa, chamando as fun√ß√µes necess√°rias para realizar a classifica√ß√£o das m√£os de p√¥quer, medir o tempo e inicialmente escolher se ser√° executado reduzindo a cardinalidade ou n√£o. Al√©m de no final, fazer o c√°lculo do resultado, relacionando a acur√°cia e o tempo de execu√ß√£o.

  #### [**`int Lac::INTERSECTION_LIMIT = 0`**](src/lac.hpp)
  Vari√°vel est√°tica que define o limite de interse√ß√£o para a an√°lise combinat√≥ria.

  #### [**`pthread_mutex_t Lac::mutex = PTHREAD_MUTEX_INITIALIZER`**](src/lac.hpp)
  Vari√°vel est√°tica que define o mutex para sincroniza√ß√£o entre threads.

</div>

#### [**`unordered_map<cacheKey, cacheValue, vectorPairHash, vectorPairEqual> Lac::similarityCache`**](src/lac.hpp)

<div align='justify'>

  Tabela de cache de similaridade para armazenar os valores de similaridade entre as linhas.

</div>

#### [**`Lac::Lac(unordered_map<pair<int, int>, unordered_set<int>, pairHash> features, unordered_map<int, unordered_set<int>> classes) )`**](src/lac.cpp)

<div align='justify'>

  Construtor da classe Lac, respons√°vel por inicializar as vari√°veis necess√°rias para a execu√ß√£o do algoritmo LAC. Sendo elas a tabela de features e a tabela de classes.

</div>

#### [**`void Lac::trainig(string path)`**](src/lac.cpp)

<div align='justify'>

  Fun√ß√£o respons√°vel por realizar a fase de treinamento do algoritmo LAC, mapeando as features e as classes presentes na base de treinamento. Nesta fun√ß√£o, √© feito a leitura do arquivo de treinamento, mapeamento das features e classes, e a redu√ß√£o da cardinalidade, caso seja escolhido. A redu√ß√£o da cardinalidade √© feita pegando os valores de uma carta e um naipe, e transformando em um valor √∫nico, de 0 a 51, para cada carta. Caso a redu√ß√£o da cardinalidade n√£o seja escolhida, o algoritmo segue normalmente, mapeando as features e classes da base de treinamento. 

</div>

#### [**`float Lac::testing(string path)`**](src/lac.cpp)

<div align='justify'>

  Essa fun√ß√£o √© respons√°vel por testar o algoritmo LAC, classificando as m√£os de p√¥quer presentes na base de teste. A fun√ß√£o segue os seguintes passos:
  1. **Abertura dos Arquivos**: Abre o arquivo de teste e o arquivo de sa√≠da.
  2. **Inicializa√ß√£o das Vari√°veis**: Inicializa as vari√°veis necess√°rias para a classifica√ß√£o. 
  -`int j = 1`: Essa vari√°vel √© usada para contar as linhas do arquivo de teste (ou seja, os exemplos sendo processados).
  - `int loss = 0`, `accuracy = 0`: Essas vari√°veis s√£o usadas para contar quantas vezes o classificador errou (loss) e quantas vezes acertou (accuracy).
  - `pthread_mutex_init(&mutex, NULL)`: Inicializa o mutex para sincroniza√ß√£o entre threads.
  3. **Processamento Linha a Linha do Arquivo de Teste**: A fun√ß√£o l√™ o arquivo linha por linha utilizando `getline(file, line)`. Para cada linha:
  - *Extra√ß√£o dos Valores*: A fun√ß√£o chama `splitString(line)` para dividir a linha em um vetor de inteiros (`values`), representando os atributos da amostra de teste e sua classe esperada (o √∫ltimo valor).
  - *Inicializa√ß√£o de Resultados*: Um array `result[]` √© inicializado com zeros. Ele ter√° o tamanho do n√∫mero de classes e ser√° preenchido com os valores de confian√ßa (suporte) para cada classe.
  - *Extra√ß√£o das Features*: A linha √© convertida em uma lista de pares `lineFeatures`, que s√£o as features (caracter√≠sticas) extra√≠das do exemplo de teste. Dependendo do valor de `DECREASE_CARDINALITY`, as features s√£o processadas de duas formas:
    - `DECREASE_CARDINALITY = true`: Os valores s√£o processados aos pares e combinados em √≠ndices. Isso parece ser uma maneira de reduzir a cardinalidade dos dados.
    `DECREASE_CARDINALITY = false`: Cada valor da linha √© considerado individualmente como uma feature.
  4. **Combinando as Features**: Aqui inicia o processo de combina√ß√£o das features. Onde: 
  - O vetor `lineFeatures` armazena os atributos (*features*) de cada linha do conjunto de dados.
  - O vetor `combinationsFeatures` √© uma estrutura que vai armazenar todas as combina√ß√µes de atributos geradas para cada exemplo de teste.
  - A fun√ß√£o `combinations(lineFeatures, q)` ser√° usada para gerar as combina√ß√µes de features, onde `q` representa o tamanho das combina√ß√µes que ser√£o geradas (1 a 1, 2 a 2, e assim por diante at√© o tamanho m√°ximo `MAX_COMBS`).
  - Tamb√©m √© definida a vari√°vel `shouldStop`, que indica se o processo de an√°lise deve ser interrompido, caso a dimens√£o do vetor de interse√ß√µes seja menor que um valor m√≠nimo (`INTERSECTION_LIMIT`).

  5. **Processamento Paralelo das Combina√ß√µes**: Aqui, o algoritmo divide o trabalho de processamento das combina√ß√µes entre v√°rias threads, para acelerar o processo. Cada thread √© respons√°vel por processar um intervalo de combina√ß√µes.
  - *Inicializa√ß√£o das Threads*:
    - Defini-se n√∫mero de threads (`numThreads = 5`) que ser√£o usadas para processar as combina√ß√µes.
    - Cada thread √© representada por um objeto `pthread_t`, e o c√≥digo cria um array de threads.
    - A estrutura `ThreadData` cont√©m os dados que ser√£o passados para cada thread.
    - A vari√°vel `chunkSize` armazena o tamanho do intervalo de combina√ß√µes que cada thread ir√° processar.

  - *Divis√£o de Tarefas*: Cada thread recebe uma estrutura de dados `ThreadData`, que cont√©m os seguintes elementos:
    - `combinationsFeatures`: Um ponteiro para o vetor de combina√ß√µes de features que a thread ir√° processar.
    - `features`: Um ponteiro para o conjunto completo de features do conjunto de dados.
    - `classes`: Um ponteiro para as classes associadas ao conjunto de dados.
    - `start` e `end`: Definem o intervalo de combina√ß√µes de features que essa thread ir√° processar.
      - `start` √© calculado como `t * chunkSize`.
      - `end` √© calculado como `(t + 1) * chunkSize`, exceto para a √∫ltima thread, que processa at√© o fim de `combinationsFeatures`.
    - `result`: Uma refer√™ncia ao vetor que armazena os resultados das classifica√ß√µes feitas pela thread.
    - `shouldStop`: Um ponteiro para a vari√°vel de controle que indica se o processamento deve parar.
    - `similarityCache`: Um ponteiro para o cache de similaridades, que pode ser usado para acelerar o c√°lculo de interse√ß√µes, evitando a recomputa√ß√£o de resultados que j√° foram processados anteriormente.
  
  - *Cria√ß√£o das Threads*: Depois de atribuir os dados, o c√≥digo cria a thread com a fun√ß√£o `pthread_create`. Cada thread executa a fun√ß√£o `threadIntersection`, que √© respons√°vel por processar as combina√ß√µes de features e calcular as interse√ß√µes.

  - *Espera pelo T√©rmino das Threads*: Ap√≥s criar todas as threads, o c√≥digo aguarda o t√©rmino de cada uma delas com a fun√ß√£o `pthread_join`.

  6. **Classifica√ß√£o das Linhas**: Ap√≥s o processamento paralelo das combina√ß√µes, o algoritmo classifica as linhas com base nas interse√ß√µes de features geradas. A fun√ß√£o `classification` √© respons√°vel por determinar a classe de cada linha com base nas interse√ß√µes de features. Logo ap√≥s, √© chamado um `pthread_mutex_destroy(&mutex)` para destruir o mutex utilizado para sincroniza√ß√£o entre threads. Depois √© escrito o resultado da classifica√ß√£o no arquivo de sa√≠da, contendo a linha e a sua classifica√ß√£o.

  7. **C√°lculo da Acur√°cia**: O algoritmo calcula a acur√°cia da classifica√ß√£o, comparando as classes reais com as classes previstas. A acur√°cia √© o n√∫mero de acertos dividido pelo n√∫mero total de exemplos de teste.

  8. **Fechamento dos Arquivos**: Por fim, o algoritmo fecha os arquivos de entrada e sa√≠da.

</div>

#### [**`vector<int> Lac::splitString(string line)`**](src/lac.cpp)

<div align='justify'>
  
  Fun√ß√£o respons√°vel por dividir uma string em um vetor de inteiros, separando os valores por v√≠rgula.

</div>

#### [**`unordered_set<int> Lac::intersectionAll(vector<unordered_set<int>> lists)`**](src/lac.cpp)

<div align='justify'>
  
  Fun√ß√£o respons√°vel por realizar a interse√ß√£o entre todas as listas de inteiros presentes em um vetor de conjuntos.

</div>

#### [**`int Lac::findMaxIndex(double* arr, int size)`**](src/lac.cpp)

<div align='justify'>

Fun√ß√£o respons√°vel por encontrar o √≠ndice do maior valor em um vetor de doubles.

</div>

#### [**`vector<unordered_set<pair<int, int>, pairHash>> Lac::combinations(const vector<pair<int, int>>& c, int k)`**](src/lac.cpp)

<div align='justify'>

  Essa fun√ß√£o recebe como par√¢metros o vetor `c` e o n√∫mero de elementos na combina√ß√£o `k`. 
  - Seu principal objetivo √© retornar um vetor contendo todas as combina√ß√µes dos elementos de `c`, cada uma com `k` valores. A fun√ß√£o utilizada foi escolhida por ser diferente das que estamos habituados a usar (as com recurs√£o ou similares), justamente pela curiosidade.
  - Ela lan√ßa m√£o de opera√ß√µes bit a bit e shifting para retornar o resultado. De forma muito simplificada, a cada itera√ß√£o ela mapeia os elementos do vetor `c` com um n√∫mero bin√°rio "comb" para informar as combina√ß√µes de `c` com `k` valores.
  - Ela inicia sempre das "combina√ß√µes" de apenas um elemento e vai at√© a de `k` elementos. Por√©m, existe uma condicional que adiciona no vetor de resultados apenas as jun√ß√µes de `k` valores.
  - **Exemplo**: Suponhamos que temos um vetor de 4 elementos: `c = {A, B, C, D}` e queremos gerar todas as combina√ß√µes de 2 elementos (`k = 2`).
    - *Inicializa√ß√£o*:
      - `n = c.size() = 4` // (n√∫mero de elementos na cole√ß√£o `c`).
      - `combo = (1 << k) - 1 = (1 << 2) - 1 = 0b11` // (ou seja, 3 em decimal), que representa a combina√ß√£o inicial `{A, B}` (os dois primeiros bits est√£o definidos como 1).

    - *Primeira Itera√ß√£o*:
      - Estado Inicial:
        - `combo = 0b0011` // (representa o primeiro e segundo elementos do vetor `c`: `(A e B)`).
      
      - Inser√ß√£o: os elementos correspondentes s√£o inseridos no vetor de combina√ß√µes no "for-loop" interno:
        - Para `i = 0`:
          - `combo >> 0` // `0b0011` (n√£o muda).
          - `(combo >> 0) & 1` // `0b0011 & 0b0001 = 0b0001 ‚Üí 1` (verdadeiro).
          - `c[i] = A` // inserido em "currentComb".
      E assim sucessivamente at√© `n`. Ap√≥s isso, como `k = 2`, nenhum desses valores √© aproveitado e o vetor "result" permanece vazio.

    - *C√°lculos*:
      - `x = combo & -combo` // `x = 0b0011 & 0b0101 = 0b0001`.
      - `y = combo + x` // `y = 0b0011 + 0b0001 = 0b0100`.
      - `z = combo & ~y` // `z = 0b0011 & ~0b0100 = 0b0011 & 0b1011 = 0b0011`.
      - `combo = z / x` // `combo = 0b0011 / 0b0001 = 0b0011`.
      - `combo >>= 1` // `combo = 0b0011 >> 1 = 0b0001`.
      - `combo |= y` // `combo = 0b0001 | 0b0100 = 0b0101`.

    - *Novo combo*:
      - `combo = 0b0101`.

    E o processo se repete at√© acabar as combina√ß√µes de `k` elementos.

</div>

#### [**`void Lac::populateCache(cacheKey lineFeatures, cacheValue classesSupport)`**](src/lac.cpp)

<div align='justify'>

  Fun√ß√£o respons√°vel por popular a cache de similaridade, armazenando os valores de similaridade entre as features de uma linha e as classes associadas a ela.

</div>

#### [**`pair<vector<double>, double> Lac::checkSimilarity(cacheKey lineFeatures)`**](src/lac.cpp)

<div align='justify'>

  Fun√ß√£o respons√°vel por verificar a similaridade entre as features de uma linha e as features presentes no cache de similaridade.
  - Nessa fun√ß√£o, √© feito um loop para percorrer todas as linhas presentes no cache de similaridade, chamando a fun√ß√£o `cosineSimilarity` para calcular a similaridade entre as features da linha e as features presentes no cache. Caso a similaridade seja maior que o threshold, a fun√ß√£o retorna um par contendo a classe da linha e a similaridade calculada.

</div>

#### [**`double Lac::cosineSimilarity(const vector<pair<int, int>>& vec1, const vector<pair<int, int>>& vec2)`**](src/lac.cpp)

<div align='justify'>

  Essa fun√ß√£o calcula a similaridade de cosseno entre dois vetores de pares de inteiros. Ela mede a similaridade entre dois vetores num espa√ßo de n-dimens√µes, independentemente de sua magnitude. A similaridade de cosseno √© amplamente utilizada em algoritmos de classifica√ß√£o e recupera√ß√£o de informa√ß√µes para medir a semelhan√ßa entre dois conjuntos de dados. Quanto maior o cosseno entre dois vetores, menor o √¢ngulo entre eles e, consequentemente, maior a similaridade. Ela funciona da seguinte forma:
  - *Produto Escalar*: O produto escalar (`dotProduct`) √© calculado somando os produtos dos segundos valores de cada par (os valores `second` de `vec1` e `vec2`).
  - *Magnitude dos Vetores*: As magnitudes dos vetores s√£o calculadas somando os quadrados dos valores do segundo elemento de cada par em `vec1` e `vec2`. Estas magnitudes s√£o usadas para normalizar o produto escalar, permitindo uma compara√ß√£o entre vetores de diferentes tamanhos.
  - *Raiz Quadrada das Magnitudes*: Ap√≥s calcular as somas dos quadrados, a fun√ß√£o tira a raiz quadrada para obter as magnitudes reais dos vetores.
  - *Retorno da Similaridade*: A similaridade de cosseno √© dada pela divis√£o do produto escalar pela multiplica√ß√£o das magnitudes dos dois vetores.
  - O valor retornado estar√° no intervalo de -1 a 1, onde:
    - 1 significa que os vetores est√£o perfeitamente alinhados (mesma dire√ß√£o).
    - 0 significa que n√£o h√° correla√ß√£o (os vetores s√£o ortogonais).
    - -1 significa que os vetores est√£o em dire√ß√µes opostas.

Em resumo similaridade de cossenos √© calculada pela f√≥rmula:

$$
cos(\theta) = \frac{A \cdot B}{||A|| \cdot ||B||}
$$

</div>

#### [**`void* Lac::threadIntersection(void* arg)`**](src/lac.cpp)

<div align='justify'>

  Essa fun√ß√£o √© o n√∫cleo da execu√ß√£o paralela no c√≥digo que trabalha com combina√ß√µes de features para realizar classifica√ß√µes. Ela √© executada por cada thread criada, e cada uma processa uma parte do conjunto de combina√ß√µes de features para calcular a interse√ß√£o entre elas e as classes.
  1. **Convers√£o do Argumento**: O argumento da fun√ß√£o (`arg`) √© convertido de `void*` para `ThreadData*`. Isso porque a fun√ß√£o `pthread_create` passa o dado como um ponteiro gen√©rico, e √© necess√°rio convert√™-lo de volta para o tipo espec√≠fico.
  2. **La√ßo de Processamento das Combina√ß√µes**: A fun√ß√£o processa as combina√ß√µes de features no intervalo entre `start` e `end` definido para a thread. Converte-se a combina√ß√£o atual (um `unordered_set` de pares) para um vetor de pares chamado `combinacoesCacheVec`.
  3. **Verifica√ß√£o no Cache de Similaridade**: Se a combina√ß√£o j√° existe no cache de similaridades (`similarityCache`), os resultados armazenados no cache s√£o diretamente somados ao vetor `result`, evitando o rec√°lculo. 
  4. **C√°culo da Similaridade de Cossenos**: Se a similaridade cosseno for ativada (`USE_COSINE_SIMILARITY`), a fun√ß√£o tentar√° calcular a similaridade entre as combina√ß√µes e as classes. √â feita a inicializa√ß√£o de `pthread_mutex_lock(&mutex)` para garantir a exclus√£o m√∫tua entre threads. Caso o resultado seja superior a um certo limiar (`THRESHOLD`), ele ser√° usado para incrementar o `result`. Depois √© feita a libera√ß√£o do mutex com `pthread_mutex_unlock(&mutex)`.
  5. **Interse√ß√£o de Linhas**: Caso a combina√ß√£o ainda n√£o tenha sido processada, a fun√ß√£o realiza a interse√ß√£o das linhas das features associadas a essa combina√ß√£o.
  - Se a combina√ß√£o contiver apenas uma *feature*, a interse√ß√£o √© simplesmente o conjunto de linhas dessa *feature*.
  - Caso contr√°rio, a fun√ß√£o `intersectionAll` √© chamada para calcular a interse√ß√£o entre todos os conjuntos de linhas.
  6. **Limite de Interse√ß√£o**: Se o n√∫mero de elementos na interse√ß√£o for inferior a um certo limite (`INTERSECTION_LIMIT`), o processamento √© interrompido para essa thread.
  7. **Verifica√ß√£o de Interse√ß√£o por Classe**: Para cada classe, o c√≥digo verifica se os elementos da interse√ß√£o pertencem a essa classe. Caso positivo, calcula a confian√ßa (n√∫mero de elementos na interse√ß√£o) e o suporte, que √© a propor√ß√£o de elementos da interse√ß√£o em rela√ß√£o ao total de features.
  - Se a confian√ßa for maior que um limite m√≠nimo (`MIN_SUPORTE`), o suporte √© somado ao vetor `result` para a classe correspondente.
  - Se a similaridade cosseno estiver ativada, o suporte tamb√©m √© adicionado ao `similarityCache`.
  8. **Atualiza√ß√£o do Cache de Similaridade**: Se o uso de similaridade cosseno estiver ativo, o suporte para a combina√ß√£o √© armazenado no cache, para evitar recalcular no futuro.
  10. **Retorno dos Resultados**: Ap√≥s processar todas as combina√ß√µes, a fun√ß√£o retorna `NULL`.

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üèÅ Conclus√£o

<div  align="justify">

  O desenvolvimento e aprimoramento do algoritmo LAC, como apresentado neste trabalho, demonstram a efic√°cia e a flexibilidade dessa abordagem na resolu√ß√£o de problemas complexos de classifica√ß√£o. As melhorias implementadas, incluindo a utiliza√ß√£o de t√©cnicas de multithreading e otimiza√ß√µes espec√≠ficas, permitiram um ganho significativo de desempenho, tornando o algoritmo mais eficiente em termos de tempo de execu√ß√£o e utiliza√ß√£o de recursos.

  Al√©m disso, a aplica√ß√£o de um cache de similaridade e a escolha criteriosa dos m√©todos de c√°lculo, como a similaridade de cossenos, refor√ßam a robustez do LAC em diferentes cen√°rios de classifica√ß√£o, especialmente em conjuntos de dados de alta dimensionalidade e com caracter√≠sticas complexas.

  Os resultados obtidos confirmam que o LAC, aliado √†s otimiza√ß√µes propostas, √© uma ferramenta poderosa para a classifica√ß√£o de grandes volumes de dados, com potencial para ser aplicado em diversas √°reas, desde a minera√ß√£o de dados at√© o aprendizado de m√°quina. O uso de cinco threads, conforme determinado pelos testes, mostrou-se a escolha mais eficaz, equilibrando a carga de trabalho e maximizando a efici√™ncia do algoritmo.

  Este trabalho abre portas para futuras pesquisas e melhorias adicionais, como a explora√ß√£o de novas t√©cnicas de otimiza√ß√£o e o estudo do impacto de diferentes estrat√©gias de paralelismo. A cont√≠nua evolu√ß√£o do LAC poder√° contribuir para sua aplica√ß√£o em contextos ainda mais desafiadores, mantendo sua relev√¢ncia no campo da ci√™ncia de dados.

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üî® Come√ßando

<div align="justify">

  Nesta se√ß√£o est√£o exemplificados os meios atrav√©s dos quais se tornam poss√≠veis a compila√ß√£o e execu√ß√£o do programa apresentado.

</div>

### Pr√©-requisitos

<div align="justify">

  Inicialmente, algumas considera√ß√µes importantes sobre como se deve preparar o ambiente para compilar e executar o programa:

</div>

> [!NOTE]
> Recomenda-se usar uma distribui√ß√£o de sistema operacional Linux ou o Windows Subsystem for Linux (WSL), pois os comandos no [`makefile`][makefile] foram selecionados para funcionar em um ambiente [_shell/bash_][bash-url].

<div align="justify">

  Considerando um ambiente _shell_, garanta que os seguintes comandos j√° foram executados:
  - Atualize os pacotes antes da instala√ß√£o dos compiladores:
  ```console
  sudo apt update
  ```
  - Instale a cole√ß√£o de compiladores ___GNU/g++___ e o ___make___:
  ```console
  sudo apt install build-essential
  ```
  - Se necess√°rio, instale o ___make___ individualmente:
  ```console
  sudo apt install make
  ```

</div>

### Instalando

<div align="justify">
  Com o ambiente preparado, os seguintes passos s√£o para a instala√ß√£o, compila√ß√£o e execu√ß√£o do programa localmente:

  1. Clone o reposit√≥rio no diret√≥rio desejado:
  ```console
  git clone https://github.com/alvarengazv/lac-algorithm.git
  cd lac-algorithm
  ```
  2. Compile o programa com o ___make___, o que gera a pasta `build`, que cont√©m arquivos de objeto e um arquivo execut√°vel:
  ```console
  make
  ```
  3. Execute o programa da pasta `build` ap√≥s a compila√ß√£o:
  ```console
  make run
  ```

  4. Se necess√°rio, apague a √∫ltima compila√ß√£o da pasta `build`:
  ```console
  make clean
  ```

  O programa estar√° pronto para ser testado. Veja a tabela abaixo com alguns comandos do makefile:

</div>

<div align="center">

  | Comando      | **Descri√ß√£o**                           |
  |--------------|-----------------------------------------|
  | `make`       | Compila o programa.                     |
  | `make run`   | Executa o programa com o arquivo de entrada fornecido. |
  | `make clean` | Remove os arquivos compilados.          |

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üß™ Ambiente de Compila√ß√£o e Execu√ß√£o

<div align="justify">

  O trabalho foi desenvolvido e testado em v√°rias configura√ß√µes de hardware. Podemos destacar algumas configura√ß√µes de Sistema Operacional e Compilador, pois as demais configura√ß√µes n√£o influenciam diretamente no desempenho do programa.

</div>

<div align='center'>

![Ubuntu][ubuntu-badge]
![GCC][gcc-badge]
![Make][make-badge] 

SO | Compilador 
--- | --- 
Ubuntu 24.04.4 LTS | g++ (Ubuntu 11.4.0-1ubuntu1~22.04)¬†11.4.0 

</div>

> [!IMPORTANT] 
> Para que os testes tenham validade, considere as especifica√ß√µes
> do ambiente de compila√ß√£o e execu√ß√£o do programa.

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üì® Contato

<div align="center">
  <br><br>
     <i>Guilherme Alvarenga de Azevedo - Graduando - 3¬∫ Per√≠odo de Engenharia de Computa√ß√£o @ CEFET-MG</i>
  <br><br>
  
  [![Gmail][gmail-badge]][gmail-autor1]
  [![Linkedin][linkedin-badge]][linkedin-autor1]
  [![Telegram][telegram-badge]][telegram-autor1]
  
  <br><br>
     <i>Jo√£o Paulo da Cunha Faria - Graduando - 3¬∫ Per√≠odo de Engenharia de Computa√ß√£o @ CEFET-MG</i>
  <br><br>
  
  [![Gmail][gmail-badge]][gmail-autor2]
  [![Linkedin][linkedin-badge]][linkedin-autor2]
  
  <br><br>
     <i>Maria Eduarda Teixeira Souza - Graduando - 3¬∫ Per√≠odo de Engenharia de Computa√ß√£o @ CEFET-MG</i>
  <br><br>
  
  [![Gmail][gmail-badge]][gmail-autor3]
  [![Linkedin][linkedin-badge]][linkedin-autor3]
  [![Telegram][telegram-badge]][telegram-autor3]
  
  <br><br>
     <i>Matheus Emanuel da Silva - Graduando - 3¬∫ Per√≠odo de Engenharia de Computa√ß√£o @ CEFET-MG</i>
  <br><br>
  
  [![Gmail][gmail-badge]][gmail-autor4]
  [![Linkedin][linkedin-badge]][linkedin-autor4]
  [![Telegram][telegram-badge]][telegram-autor4]

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

<a name="referencias">üìö Refer√™ncias</a>

[^1]: A. A. Veloso, "Classifica√ß√£o associativa sob demanda," Ph.D. disserta√ß√£o, Departamento de Ci√™ncia da Computa√ß√£o, Universidade Federal de Minas Gerais, Belo Horizonte, Brasil, 2009.

[^2]: R. Cattral and F. Oppacher, *Poker Hand*, UCI Machine Learning Repository, 2007. [Online]. Available: https://doi.org/10.24432/C5KW38.

[^3]: Microsoft, "pair structure," Microsoft Learn, 2024. [Online]. Available: https://learn.microsoft.com/pt-br/cpp/standard-library/pair-structure?view=msvc-170. [Accessed: Aug. 30, 2024].

[^4]: Microsoft, "unordered_map class," Microsoft Learn, [Online]. Available: https://learn.microsoft.com/pt-br/cpp/standard-library/unordered-map-class?view=msvc-170. [Accessed: Aug. 30, 2024].

[^5]: Microsoft, "vector class," Microsoft Learn, [Online]. Available: https://learn.microsoft.com/pt-br/cpp/standard-library/vector-class?view=msvc-170. [Accessed: Aug. 30, 2024].

[^6]: L. He, Z. Gao, Q. Liu, e Z. Yang, "An Improved Grid Search Algorithm for Parameters Optimization on SVM," Applied Mechanics and Materials, vol. 644-650, pp. 2216-2221, 2014. DOI: 10.4028/www.scientific.net/AMM.644-650.2216.

[^7]: "unordered_set Class | Microsoft Learn," Microsoft, [Online]. Available: https://learn.microsoft.com/pt-br/cpp/standard-library/unordered-set-class?view=msvc-170. [Accessed: 29-Aug-2024].


[vscode-badge]: https://img.shields.io/badge/Visual%20Studio%20Code-0078d7.svg?style=for-the-badge&logo=visual-studio-code&logoColor=white
[vscode-url]: https://code.visualstudio.com/docs/?dv=linux64_deb
[make-badge]: https://img.shields.io/badge/_-MAKEFILE-427819.svg?style=for-the-badge
[make-url]: https://www.gnu.org/software/make/manual/make.html
[cpp-badge]: https://img.shields.io/badge/c++-%2300599C.svg?style=for-the-badge&logo=c%2B%2B&logoColor=white
[cpp-url]: https://en.cppreference.com/w/cpp
[github-prof]: https://github.com/mpiress
[main-ref]: src/main.cpp
[branchAMM-url]: https://github.com/alvarengazv/trabalhosAEDS1/tree/AlgoritmosMinMax
[makefile]: ./makefile
[bash-url]: https://www.hostgator.com.br/blog/o-que-e-bash/
[lenovo-badge]: https://img.shields.io/badge/lenovo%20laptop-E2231A?style=for-the-badge&logo=lenovo&logoColor=white
[ubuntu-badge]: https://img.shields.io/badge/Ubuntu-E95420?style=for-the-badge&logo=ubuntu&logoColor=white
[Ubuntu-url]: https://ubuntu.com/
[ryzen5500-badge]: https://img.shields.io/badge/AMD%20Ryzen_5_5500U-ED1C24?style=for-the-badge&logo=amd&logoColor=white
[ryzen3500-badge]: https://img.shields.io/badge/AMD%20Ryzen_5_3500X-ED1C24?style=for-the-badge&logo=amd&logoColor=white
[windows-badge]: https://img.shields.io/badge/Windows-0078D6?style=for-the-badge&logo=windows&logoColor=white
[gcc-badge]: https://img.shields.io/badge/GCC-5C6EB8?style=for-the-badge&logo=gnu&logoColor=white

[trabalho-url]:https://drive.google.com/file/d/11tvEmPrVSYZFsJzXbcc15Ags8CLRJByU/view?usp=sharing
[grid-search]: https://github.com/alvarengazv/lac-algorithm/tree/grid-search

[linkedin-autor1]: https://www.linkedin.com/in/guilherme-alvarenga-de-azevedo-959474201/
[telegram-autor1]: https://t.me/alvarengazv
[gmail-autor1]: mailto:gui.alvarengas234@gmail.com

[linkedin-autor2]: https://www.linkedin.com/in/jo%C3%A3o-paulo-cunha-faria-219584270/
[gmail-autor2]: mailto:joaopaulofaria98@gmail.com

[linkedin-autor3]: https://www.linkedin.com/in/maria-eduarda-teixeira-souza-2a2b3a254   
[telegram-autor3]: https://t.me/dudat_18
[gmail-autor3]: mailto:dudateixeirasouza@gmail.com

[linkedin-autor4]: https://www.linkedin.com/
[telegram-autor4]: https://t.me/
[gmail-autor4]: mailto:memanuel643@gmail.com

[linkedin-badge]: https://img.shields.io/badge/-LinkedIn-0077B5?style=for-the-badge&logo=Linkedin&logoColor=white
[telegram-badge]: https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&logo=telegram&logoColor=white
[gmail-badge]: https://img.shields.io/badge/-Gmail-D14836?style=for-the-badge&logo=Gmail&logoColor=white
