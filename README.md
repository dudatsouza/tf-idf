<a name="readme-topo"></a>

<h1 align='center'>
  üìä Ranqueamento de Documentos - TF/IDF
</h1>

<div align='center'>

[![SO][Ubuntu-badge]][Ubuntu-url]
[![IDE][vscode-badge]][vscode-url]
[![Make][make-badge]][make-url]
[![Linguagem][cpp-badge]][cpp-url]

Algoritmos e Estruturas de Dados II <br>
Engenharia de Computa√ß√£o <br>
Prof. Michel Pires da Silva <br>
CEFET-MG Campus V <br>
2024/2
</div>

<details>
  <summary>
  <b style='font-size: 15px'>
    üìë Sum√°rio
  </b>
  </summary>
  <ol>
    <li><a href="#-introdu√ß√£o">üîç Introdu√ß√£o</a></li>
    <li>
      <a href="#-fundamenta√ß√£o-te√≥rica">üí° Fundamenta√ß√£o Te√≥rica</a>
    </li>
    <li>
      <a href="#-objetivos">üéØ Objetivos</a>
      <ul>
        <li><a href='#objetivo-geral'>Objetivo Geral</a></li>
        <li><a href='#objetivos-espec√≠ficos'>Objetivos Espec√≠ficos</a></li>
      </ul>
    </li>
    <li>
      <a href="#-modelagem-de-aplica√ß√£o">üî¨ Modelagem de Aplica√ß√£o</a>
    </li>
    <li>
      <a href="#%EF%B8%8F-metodologia">üó≥Ô∏è Metodologia</a>
      <ul>
        <li><a href='#-arquivos'>Arquivos</a></li>
        <li><a href='#-bibliotecas'>Bibliotecas</a></li>
        <li><a href='#defini√ß√µes-e-estruturas-usadas'>Defini√ß√µes e Estruturas Usadas</a></li>
        <li><a href='#-fun√ß√µes-implementadas'>Fun√ß√µes Implementadas</a></li>
      </ul>
    </li>
    <li>
      <a href="#-testes-e-an√°lises-dos-resultados">üìä Testes e An√°lises dos Resultados</a>
    </li>
    <li><a href="#-conclus√£o">üèÅ Conclus√£o</a></li>
    <li>
      <a href="#-come√ßando">üî® Come√ßando</a>
      <ul>
        <li><a href="#pr√©-requisitos">Pr√©-requisitos</a></li>
        <li><a href="#instalando">Instalando</a></li>
      </ul>
    </li>
    <li><a href="#-ambiente-de-compila√ß√£o-e-execu√ß√£o">üß™ Ambiente de Compila√ß√£o e Execu√ß√£o</a></li>
    <li><a href="#-contato">üì® Contato</a></li>
    <li><a href="#referencias">üìö Refer√™ncias</a></li>
  </ol>
</details>

<details> 
  <summary>
    <b style='font-size: 12px'> Abstract </b> 
  </summary>

  Este projeto explora o ranqueamento de documentos com base na t√©cnica **TF-IDF** (*Term Frequency-Inverse Document Frequency*), aplicada no contexto de estruturas de dados. A implementa√ß√£o em C++ utiliza tanto *Hash Table* quanto *lista encadeada* para armazenar a frequ√™ncia de termos nos documentos, permitindo uma an√°lise comparativa de desempenho entre essas estruturas. O algoritmo **TF-IDF** ranqueia documentos de forma eficaz e precisa de acordo com termos de busca espec√≠ficos, com ganho significativo de efici√™ncia ao utilizar a *Hash Table* otimizada. Al√©m disso, o projeto discute abordagens alternativas, como √°rvores e grafos, que podem capturar rela√ß√µes sem√¢nticas mais complexas entre documentos em aplica√ß√µes futuras. 


  üîë <b>Keywords:</b> TF-IDF, ranqueamento de documentos, Hash Table, lista encadeada, estruturas de dados.
<br>
</details>

## üîç Introdu√ß√£o

<div align='justify'>

  Este [trabalho][trabalho-url] (Ranqueamento de Documentos) foi proposto na disciplina de Algoritmos e Estruturas de Dados II (AEDSII) pelo professor [Michel Pires da Silva][github-prof].

  O ranqueamento de documentos √© uma t√©cnica utilizada para ordenar documentos de acordo com sua relev√¢ncia em rela√ß√£o a uma consulta. A t√©cnica TF-IDF (Term Frequency-Inverse Document Frequency) √© uma das mais utilizadas nesse contexto e, por sua simplicidade e efici√™ncia, foi escolhida para ser testada neste trabalho.

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üí° Fundamenta√ß√£o Te√≥rica

<div align='justify'>

  Em 1972, **Karen Sp√§rck Jones** prop√¥s a t√©cnica TF-IDF no *Journal of Documentation* em um artigo chamado "A statistical interpretation of term specificity and its application in retrieval", onde ela, al√©m de propor este algoritmo, tamb√©m prop√¥s outras t√©cnicas de ranqueamento de documentos [^1].

  Neste trabalho, utilizou-se um pouco da ideia deste algoritmo para fazer o ranqueamento os documentos. 
  
  A t√©cnica TF-IDF √© uma t√©cnica de ranqueamento de documentos que leva em considera√ß√£o a frequ√™ncia de um termo em um documento e a frequ√™ncia inversa de um termo em todos os documentos. A t√©cnica √© composta por duas partes: a frequ√™ncia de um termo em um documento (TF) e a frequ√™ncia inversa de um termo em todos os documentos (IDF).

  ### TF (Term Frequency)
  √â a frequ√™ncia de um termo em um documento. Ela √© calculada apartir da quantidade de vezes que um termo aparece em um documento, dividido pela soma das frequ√™ncias de todos os termos no documento. A frequ√™ncia de um termo em um documento √© calculada pela f√≥rmula:

  $$f_{t,d} = \frac{f_{t,d}}{\sum_{t' \in d} f_{t',d}}$$

  Onde:
  - $f_{t,d}$ √© a frequ√™ncia do termo t no documento d.
  - $\sum_{t' \in d} f_{t',d}$ √© a soma das frequ√™ncias de todos os termos no documento d. 

  ### IDF (Inverse Document Frequency)
  √â a frequ√™ncia inversa de um termo em todos os documentos. Ela √© calculada apartir da quantidade de documentos que cont√©m um termo, dividido pelo total de documentos. A frequ√™ncia inversa de um termo em todos os documentos √© calculada pela f√≥rmula: 

  $$idf_t = \log\left(\frac{N}{n_t}\right)$$

  Onde:
  - $N$ √© o total de documentos.
  - $n_t$ √© a quantidade de documentos que cont√©m o termo t.

  ### TF-IDF (Term Frequency-Inverse Document Frequency)

  O fator TF-IDF √© calculado multiplicando-se a frequ√™ncia de um termo em um documento pela frequ√™ncia inversa de um termo em todos os documentos. A f√≥rmula para o c√°lculo do fator TF-IDF √©: 

  $$tfidf_{t,d} = f_{t,d} \times idf_t$$

  Onde:
  - $tfidf_{t,d}$ √© o fator TF-IDF do termo t no documento d.
  - $f_{t,d}$ √© a frequ√™ncia do termo t no documento d.
  - $idf_t$ √© a frequ√™ncia inversa do termo t em todos os documentos.

  ### Relev√¢ncia dos Documentos

  A relev√¢ncia dos documentos √© calculada somando-se os fatores TF-IDF de cada termo da frase buscada em cada documento. A relev√¢ncia de um documento √© calculada pela f√≥rmula:

  $$relevance_d = \sum_{t \in q} tfidf_{t,d}$$

  Onde:
  - $relevance_d$ √© a relev√¢ncia do documento d.
  - $q$ √© a frase buscada.
  - $tfidf_{t,d}$ √© o fator TF-IDF do termo t no documento d.

  ### Ranqueamento dos Documentos

  Ap√≥s o c√°lculo da relev√¢ncia dos documentos, eles s√£o ordenados em ordem crescente de relev√¢ncia. O documento com maior relev√¢ncia √© o primeiro da lista e o documento com menor relev√¢ncia √© o √∫ltimo.

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üéØ Objetivos

<div align="justify">

  ### Objetivo Geral
  O objetivo deste trabalho √© de, atrav√©s da utiliza√ß√£o das estruturas de dados j√° estudadas at√© o momento, implementar um algoritmo de ranqueamento de documentos que lan√ßa m√£o da t√©cnica TF-IDF (Term Frequency-Inverse Document Frequency).

  ### Objetivos Espec√≠ficos
  - Abordar e refor√ßar conceitos de an√°lise de algoritmos e estruturas de dados j√° explorados no contexto da disciplina.
  - Refletir sobre como novas estruturas de dados, como as √°rvores bin√°rias e os grafos, podem influenciar na resolu√ß√£o do problema proposto e quais ganhos de efici√™ncia poderiam ser alcan√ßados.

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üî¨ Modelagem de Aplica√ß√£o 

<div aling='justify'>

  A partir dos conceitos e do entendimento absorvido sobre o algoritmo, a implementa√ß√£o √© um passo de extrema import√¢ncia para garantir que os resultados sejam satisfat√≥rios. Veremos as implementa√ß√µes, escolhas e otimiza√ß√µes feitas para obter um melhor desempenho do algoritmo e uma melhor precis√£o dos resultados, detalhando onde cada aspecto est√° no c√≥digo e como as estruturas foram realmente utilizadas.

  ### Leitura dos Documentos

  No in√≠cio do programa, todos os documentos s√£o lidos e cada palavra √© adicionada em uma lista ou em uma Hash Table. No c√≥digo, essa parte est√° implementada nas fun√ß√µes [`readFile()`](src/document.cpp) e [`addWord()`](src/document.cpp) localizada no arquivo [`document.cpp`](src/document.cpp). Durante a leitura, cada palavra √© processada e armazenada conforme a estrutura de dados selecionada. A Hash Table ([`wordsFreq`](src/document.hpp)) foi utilizada na vers√£o otimizada devido ao acesso r√°pido, o que melhora o desempenho ao lidar com grandes quantidades de documentos e termos. J√° a lista encadeada ([`docWords`](src/document.cpp)) foi usada como uma alternativa para explorar a implementa√ß√£o com estruturas de dados cl√°ssicas, atendendo ao objetivo pedag√≥gico do projeto e permitindo uma compara√ß√£o direta entre as duas abordagens.

  Cada palavra que foi armazenada na estrutura de dados foi colocada como uma [`struct WordFreq`](src/document.hpp) que cont√©m o termo e a frequ√™ncia do termo no documento. A estrutura [`wordsFreq`](src/document.hpp) foi definida no arquivo [`document.hpp`](src/document.hpp).

  A escolha entre Hash Table e lista √© feita por meio de um par√¢metro de configura√ß√£o definido pelo usu√°rio em um [`#define OPTIMIZE`](src/document.hpp) no programa. Essa flexibilidade foi implementada para permitir a compara√ß√£o do desempenho e da efic√°cia de ambas as abordagens.

  ### Normaliza√ß√£o dos Textos

  As palavras lidas dos textos s√£o armazenadas nas estruturas em uma forma normalizada. Durante o processo de normaliza√ß√£o, s√£o removidos caracteres n√£o alfanum√©ricos, acentos s√£o retirados das letras e as palavras s√£o convertidas para letras min√∫sculas. Esse processo √© implementado na fun√ß√£o [`normalize()`](src/document.cpp), tamb√©m presente no arquivo [`document.cpp`](src/document.cpp). A fun√ß√£o utiliza a biblioteca [`<algorithm>`](https://www.cplusplus.com/reference/algorithm/) a fun√ß√£o [`std::transform()`](https://www.cplusplus.com/reference/algorithm/transform/) para convers√£o em min√∫sculas e uma l√≥gica customizada para remo√ß√£o de acentos e caracteres especiais. Esse procedimento visa garantir que palavras semelhantes, mas escritas de formas ligeiramente diferentes, sejam tratadas como equivalentes, aumentando a precis√£o do ranqueamento. Al√©m disso, cont√©m o `namespace` [`std::codecvt_utf8_utf16`](https://www.cplusplus.com/reference/locale/codecvt_utf8_utf16/), da biblioteca [`<codecvt>`](https://www.cplusplus.com/reference/locale/codecvt/)  temos as classes [`std::wstring_convert`](https://www.cplusplus.com/reference/locale/wstring_convert/) e [`std::codecvt_utf8_utf16`](https://www.cplusplus.com/reference/locale/codecvt_utf8_utf16/), que s√£o utilizadas para converter strings de e para wide strings e tamb√©m [`<cwchar>`](https://www.cplusplus.com/reference/cwchar/), que cont√©m fun√ß√µes para manipula√ß√£o de wide strings.

  ### C√°lculo do TF-IDF

  Para ranquear os documentos, foi utilizado o algoritmo TF-IDF (Term Frequency-Inverse Document Frequency). A implementa√ß√£o do c√°lculo do TF-IDF est√° presente no arquivo [`ranking.cpp`](src/ranking.cpp), nas fun√ß√µes [`calculareIDF()`](src/ranking.cpp), [`calculateTFIDF()`](src/ranking.cpp) e [`calculateRelevanceDoc()`](src/ranking.cpp). N√£o √© necess√°rio calcular o TF diretamente pois a frequ√™ncia de cada termo em cada documento j√° foi calculada durante a leitura dos documentos. 

  Primeiro, o calculo da frequ√™ncia (TF) de cada termo em cada documento √© feito durante a leitura dos documentos. Em seguida, √© calculada a frequ√™ncia inversa de cada termo em todos os documentos (IDF) e armazenada em uma Hash Table ([`wordsidf`](src/document.hpp)). Por fins de implemeta√ß√£o, foi feita a soma de `+1` tanto no numerador quanto no denominador para evitar divis√£o por zero, ficando ent√£o a f√≥rmula de c√°lculo do IDF da seguinte forma:

  $$idf_t = \log\left(\frac{N+1}{n_t+1}\right)$$
  
  
  Depois, o fator TF-IDF de cada termo em cada documento √© calculado na fun√ß√£o [`calculateTFIDF()`](src/ranking.cpp). O c√°lculo do fator TF-IDF √© feito multiplicando-se a frequ√™ncia de um termo em um documento pela frequ√™ncia inversa de um termo em todos os documentos. 

  ### Ranqueamento dos Documentos

  Ap√≥s o c√°lculo do TF-IDF, os documentos s√£o ranqueados em ordem crescente de relev√¢ncia. A relev√¢ncia de cada documento √© calculada somando-se os fatores TF-IDF de cada termo da frase buscada em cada documento. A relev√¢ncia de cada documento √© armazenada na v√°riavel `relevance` que √© pa√¢metro da classe [Document](src/document.hpp). A fun√ß√£o [`calculateRelevanceDoc()`](src/ranking.cpp) √© respons√°vel por calcular a relev√¢ncia de cada documento. 

  ### Ordena√ß√£o dos Documentos

  Ap√≥s o c√°lculo da relev√¢ncia dos documentos, eles s√£o ordenados em ordem crescente de relev√¢ncia. A ordena√ß√£o √© feita utilizando a fun√ß√£o [`quickSort()`](src/ranking.cpp) e a fun√ß√£o [`partition()`](src/ranking.cpp) que est√£o presentes no arquivo [`ranking.cpp`](src/ranking.cpp). A fun√ß√£o [`quickSort()`](src/ranking.cpp) √© respons√°vel por chamar a fun√ß√£o [`partition()`](src/ranking.cpp) recursivamente para ordenar os documentos. A fun√ß√£o [`partition()`](src/ranking.cpp) √© respons√°vel por dividir o vetor de documentos em duas partes e orden√°-las de acordo com a relev√¢ncia. 
  
  Com a orienta√ß√£o do professor, tivemos duas op√ß√µes de implementa√ß√£o para a ordena√ß√£o dos documentos: a primeira foi a utiliza√ß√£o do algoritmo de ordena√ß√£o QuickSort e a segunda foi a utiliza√ß√£o do algoritmo de ordena√ß√£o MergeSort. A escolha do algoritmo de ordena√ß√£o foi feita por meio de um pequeno estudo de desempenho, dificuldade de implementa√ß√£o e complexidade do algoritmo. A implementa√ß√£o do algoritmo de ordena√ß√£o QuickSort foi escolhida por ser um algoritmo de ordena√ß√£o mais simples e eficiente para o problema proposto.

  ### Estrutura de Dados Utilizada

  Durante o desenvolvimento do algoritmo, foram exploradas diferentes estruturas de dados. A Hash Table foi escolhida para a vers√£o otimizada devido ao acesso r√°pido, o que melhora o desempenho do programa ao lidar com grandes quantidades de documentos e termos. A lista encadeada foi utilizada como uma op√ß√£o alternativa, atendendo ao objetivo pedag√≥gico de explorar a implementa√ß√£o com estruturas cl√°ssicas e compar√°-la √† abordagem otimizada. No c√≥digo, a estrutura de Hash Table foi implementada com a biblioteca [`<unordered_map>`](https://www.cplusplus.com/reference/unordered_map/), enquanto a lista encadeada foi implementada utilizando a [`std::list`](https://www.cplusplus.com/reference/list/list/) da biblioteca padr√£o do C++.

</div>

## üó≥Ô∏è Metodologia

<div align="justify">

  As abordagens propostas para otimizar o algoritmo de ranqueamento foram implementadas em C++, utilizando a IDE Visual Studio Code para o desenvolvimento do c√≥digo-fonte. O projeto foi organizado em um diret√≥rio principal, contendo subdiret√≥rios para armazenar os arquivos de c√≥digo-fonte e os datasets utilizados. A solu√ß√£o proposta com a aplica√ß√£o da t√©cnica TF-IDF para o ranqueamento foi dividida em classes, cada uma respons√°vel por uma etapa do processo. A primeira, [Ranking](src/ranking.hpp), recebe as frases a serem buscadas, armazena as stopwords e l√™ os documentos para criar objetos da classe [Document](src/document.hpp), que armazenam os termos normalizados e suas frequ√™ncias. Ap√≥s isso, existe a etapa de c√°lculo da relev√¢ncia dos termos, atrav√©s de seus fatores TF/IDF em cada documento. E, por fim, a ordena√ß√£o dos documentos em ordem decrescente de relev√¢ncia.

  ### üìÅ Arquivos 

  Para a implementa√ß√£o do algoritmo, o projeto foi organizado em um diret√≥rio principal, contendo subdiret√≥rios para armazenar os arquivos de c√≥digo-fonte e os datasets utilizados. A seguir, s√£o apresentados os arquivos e diret√≥rios utilizados no projeto:

  - [datasets/](datasets): diret√≥rio contendo os datasets utilizados.
    - [doc1.txt](datasets/doc1.txt): Primeiro documento a ser consultado, o livro "A M√£o e A Luva", de Machado de Assis.
    - [doc2.txt](datasets/doc2.txt): Segundo documento a ser consultado, A B√≠blia Sagrada.
    - [doc3.txt](datasets/doc3.txt): Terceiro documento a ser consultado, o livro "Dom Casmurro", de Machado de Assis.
    - [doc4.txt](datasets/doc4.txt): Quarto documento a ser consultado, o livro "Quincas Borba", de Machado de Assis.
    - [doc5.txt](datasets/doc5.txt): Quinto documento a ser consultado, o livro "A Semana", de Machado de Assis.
    - [doc6.txt](datasets/doc6.txt): Sexto documento a ser consultado, o relato hist√≥rico "Rela√ß√£o do formidavel, e lastimoso terremoto succedido no Reino de Valen√ßa".
    - [stopwords.txt](datasets/stopwords.txt): arquivo contendo as stopwords utilizadas da l√≠ngua portuguesa. Isto √©, as palavras que n√£o possuem relev√¢ncia para o ranqueamento dos documentos. Exemplo de algumas stopwords: a, ao,aos, √†, √†s, um, uma, uns, umas, o, os, da, das, de, do, dos, e, ou, que, se, por, para, com, sem, sob, sobre, entre, etc.

  - [src/](src): diret√≥rio contendo os arquivos de c√≥digo-fonte do projeto.
    - [document.cpp](src/document.cpp): Arquivo de c√≥digo-fonte que cont√©m a implementa√ß√£o dos m√©todos da classe Document, respons√°vel por ler e representar os documentos, al√©m de normalizar os termos que os comp√µem.
    - [document.hpp](src/document.hpp): Arquivo de cabe√ßalho que cont√©m a defini√ß√£o da classe Document, respons√°vel por representar um documento a ser ranqueado.
    - [main.cpp](src/main.cpp): arquivo contendo a fun√ß√£o principal do programa, respons√°vel por fazer chamadas de fun√ß√µes que realizam  o ranqueamento dos documentos.
    - [ranking.cpp](src/ranking.cpp): Arquivo de c√≥digo-fonte que cont√©m a implementa√ß√£o dos m√©todos da classe Ranking, respons√°vel por ler as frases a serem buscadas, armazenar as stopwords e calcular o fator TF/IDF de cada documento para cada termo e ranque√°-los em ordem decrescente.
    - [ranking.hpp](src/ranking.hpp): Arquivo de cabe√ßalho que cont√©m a defini√ß√£o da classe Ranking, respons√°vel por ranquear os documentos.

  - [.gitignore](.gitignore): arquivo contendo a lista de arquivos e diret√≥rios a serem ignorados pelo Git.
  - [make.sh](make.sh): arquivo de script para compilar o c√≥digo-fonte do projeto.
  - [makefile](makefile): arquivo contendo as regras para compilar o c√≥digo-fonte do projeto.
  - [README.md](README.md): arquivo contendo a documenta√ß√£o do projeto.

  De uma forma compacta e organizada, os arquivos e diret√≥rios est√£o dispostos da seguinte forma:

  ```.
  |
  ‚îú‚îÄ‚îÄ datasets
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ doc1.txt
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ doc2.txt
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ doc3.txt
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ doc4.txt
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ doc5.txt
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ doc6.txt
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stopwords.txt
  ‚îú‚îÄ‚îÄ src
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document.cpp
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document.hpp
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.cpp
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ranking.cpp
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ranking.hpp
  ‚îú‚îÄ‚îÄ .gitignore
  ‚îú‚îÄ‚îÄ make.sh
  ‚îú‚îÄ‚îÄ makefile
  ‚îî‚îÄ‚îÄ README.md
  ```

  
</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

### üìö Bibliotecas

<div align="justify">

  As bibliotecas utilizadas na implementa√ß√£o do algoritmo LAC s√£o as seguintes:

  - [bits/stdc++.h](https://www.geeksforgeeks.org/bitsstdc-h-c-include/): biblioteca que inclui todas as bibliotecas padr√£o da linguagem C++. Veja abaixo as bibliotecas que usamos da bits/stdc++.h:
    - [iostream](https://www.cplusplus.com/reference/iostream/): biblioteca padr√£o de entrada e sa√≠da de dados.
    - [fstream](https://www.cplusplus.com/reference/fstream/): biblioteca para manipula√ß√£o de arquivos. 
    - [sstream](https://www.cplusplus.com/reference/sstream/): biblioteca para manipula√ß√£o de strings.
    - [string](https://www.cplusplus.com/reference/string/): biblioteca para manipula√ß√£o de strings.
    - [cmath](https://www.cplusplus.com/reference/cmath/): biblioteca para fun√ß√µes matem√°ticas.
    - [vector](https://www.cplusplus.com/reference/vector/): biblioteca para manipula√ß√£o de vetores.
    - [unordered_map](https://www.cplusplus.com/reference/unordered_map/): biblioteca para manipula√ß√£o de tabelas hash.
    - [unordered_set](https://www.cplusplus.com/reference/unordered_set/): biblioteca para manipula√ß√£o de conjuntos hash.
    - [list](https://cplusplus.com/reference/list/list/): biblioteca para utiliza√ß√£o de listas duplamente encadeadas.
    - [algorithm](https://www.cplusplus.com/reference/algorithm/): biblioteca para utiliza√ß√£o de algoritmos √∫teis j√° prontos.
    - [codecvt](https://www.cplusplus.com/reference/locale/codecvt/): biblioteca para manipula√ß√£o de strings.
    - [cwchar](https://www.cplusplus.com/reference/cwchar/): biblioteca para manipula√ß√£o de wide strings.
  
</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

### Defini√ß√µes e Estruturas Usadas

<div align="justify">

  Para a implementa√ß√£o do algoritmo, temos dois arquivos de cabe√ßalho e dois arquivos de c√≥digo-fonte. Os arquivos de cabe√ßalho s√£o respons√°veis por definir as classes e estruturas utilizadas no projeto, enquanto os arquivos de c√≥digo-fonte cont√™m a implementa√ß√£o dos m√©todos dessas classes e estruturas. Os arquivos de cabe√ßalho s√£o:
  
  #### Arquivo [document.hpp](src/document.hpp)

  Neste arquivo, temos a defini√ß√£o da classe [`Document`](src/document.hpp), e inclui as declara√ß√µes dos m√©todos e atributos que manipulam os documentos. A seguir est√£o os m√©todos e atributos da classe [`Document`](src/document.hpp):
  - [`#define OPTIMIZE 1`](src/document.hpp): define o tipo de estrutura de dados a ser utilizada. Se `OPTIMIZE` for 1, a estrutura de dados utilizada ser√° a Hash Table. Se `OPTIMIZE` for 0, a estrutura de dados utilizada ser√° a lista encadeada.
  - [`std::string normalize(const std::string &word);`](src/document.hpp): m√©todo que normaliza uma palavra, removendo caracteres n√£o alfanum√©ricos, acentos e convertendo para letras min√∫sculas.
  - [`struct WordFreq`](src/document.hpp): estrutura que armazena um termo e sua frequ√™ncia em um documento.
  - [`class Document`](src/document.hpp): classe que representa um documento a ser ranqueado:
    - [`Document(const std::string &filename, std::unordered_set<std::string> stopWords)`](src/document.hpp): construtor da classe [`Document`](src/document.hpp), que recebe o nome do arquivo do documento e um conjunto de stopwords.
    - [` std::unordered_set<std::string> stopWords`](src/document.hpp): conjunto de stopwords. 
    - [`double relevance = 0`](src/document.hpp): relev√¢ncia do documento.
    - [`std::string filename`](src/document.hpp): nome do arquivo do documento.
    - [`std::unordered_map<std::string, int> wordsFreq`](src/document.hpp): tabela hash que armazena os termos e suas frequ√™ncias no documento.
    - [`std::list<WordFreq> docWords`](src/document.hpp): lista encadeada que armazena os termos e suas frequ√™ncias no documento.
    - [`int totalWords = 0`](src/document.hpp): total de palavras no documento.
    - [`void readFile()`](src/document.hpp): m√©todo que l√™ o arquivo do documento e armazena os termos e suas frequ√™ncias na estrutura de dados selecionada.
    - [`void addWord(const std::string &word)`](src/document.hpp): m√©todo que adiciona um termo na estrutura de dados selecionada.
    - [`void imprimindoPalavras()`](src/document.hpp): m√©todo que imprime os termos e suas frequ√™ncias no documento.
    - [`bool operator==(const Document &other) const`](src/document.hpp): sobrecarga do operador de igualdade para a classe [`Document`](src/document.hpp).
  
  - [`namespace std`](src/document.hpp): namespace que cont√©m a defini√ß√£o da fun√ß√£o de hash para a classe [`Document`](src/document.hpp).

  #### Arquivo [ranking.hpp](src/ranking.hpp)

  Neste arquivo, temos a defini√ß√£o da classe [`Ranking`](src/ranking.hpp), e inclui as declara√ß√µes dos m√©todos e atributos que manipulam o ranqueamento dos documentos. A seguir est√£o os m√©todos e atributos da classe [`Ranking`](src/ranking.hpp):

  - [`class Ranking`](src/ranking.hpp): classe que ranqueia os documentos:
    - [`struct pairHash`](src/ranking.hpp): estrutura que define a fun√ß√£o de hash para um par de strings.
    - [`private:`](src/ranking.hpp): se√ß√£o privada da classe [`Ranking`](src/ranking.hpp).
      - [`std::vector<std::string> filenames`](src/ranking.hpp): vetor que armazena os nomes dos arquivos dos documentos.
    - [`public:`](src/ranking.hpp): se√ß√£o p√∫blica da classe [`Ranking`](src/ranking.hpp).
      - [`Ranking(std::string phrase)`](src/ranking.hpp): construtor da classe [`Ranking`](src/ranking.hpp), que recebe a frase buscada.
      - [`std::list<Document> documents`](src/ranking.hpp): lista encadeada que armazena os documentos.
      - [`std::unordered_set<std::string> stopWords`](src/ranking.hpp): conjunto de stopwords.
      - [`std::list<std::string> phraseWords`](src/ranking.hpp): lista encadeada que armazena os termos da frase buscada.
      - [`std::unordered_map<std::string, double> wordsidf`](src/ranking.hpp): tabela hash que armazena os termos e suas frequ√™ncias inversas em todos os documentos.
      - [`void readStopWords()`](src/ranking.hpp): m√©todo que l√™ as stopwords.
      - [`void readPhrase(const std::string &phrase)`](src/ranking.hpp): m√©todo que l√™ a frase buscada.
      - [`double calculateIDF(const std::string &word)`](src/ranking.hpp): m√©todo que calcula a frequ√™ncia inversa de um termo em todos os documentos.
      - [`double calculateTFIDF(const std::string &term, Document doc)`](src/ranking.hpp): m√©todo que calcula o fator TF-IDF de um termo em um documento.
      - [`void calculateRelevanceDoc()`](src/ranking.hpp): m√©todo que calcula a relev√¢ncia dos documentos.
      - [`void quickSort(std::list<Document> &documents, int left, int right)`](src/ranking.hpp): m√©todo que ordena os documentos em ordem decrescente de relev√¢ncia.
      - [`int partition(std::list<Document> &documents, int left, int right)`](src/ranking.hpp): m√©todo que divide o vetor de documentos em duas partes e ordena-os de acordo com a relev√¢ncia.

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

### üìù Fun√ß√µes Implementadas

<div  align="justify">
  
  As fun√ß√µes implementadas no projeto s√£o respons√°veis por realizar a leitura dos documentos, normalizar os termos, calcular o fator TF/IDF de cada termo em cada documento, calcular a relev√¢ncia dos documentos e orden√°-los em ordem decrescente de relev√¢ncia. A seguir, s√£o apresentadas as fun√ß√µes implementadas no projeto:

</div>

  #### Arquivo [main.cpp](src/main.cpp)

  Arquivo principal que inicializa o programa, carrega documentos, realiza buscas e exibe os resultados.

  - **Fun√ß√£o [`main()`](src/main.cpp)**: Define uma lista de frases de busca e, para cada frase: 
    1. Inicializa um objeto `Ranking` com a frase.
    2. Calcula a relev√¢ncia dos documentos.
    3. Ordena os documentos pela relev√¢ncia.
    4. Exibe o nome e a relev√¢ncia de cada documento no console.

  #### Arquivo [document.cpp](src/document.cpp)

  Arquivo que cont√©m a implementa√ß√£o dos m√©todos da classe `Document`, respons√°vel por ler e representar os documentos, al√©m de normalizar os termos que os comp√µem.

  - **Construtor[ `Document(const std::string &filename, std::unordered_set<std::string> stopWords)`](src/document.cpp)**: Construtor que inicializa `filename` e `stopWords`, chamando `readFile()` para processar o conte√∫do do arquivo.

  - **M√©todo [`void Document::readFile()`](src/document.cpp)**: 
    1. L√™ cada palavra do arquivo, ignora palavras de parada e normaliza as palavras restantes. 
    2. Remove caracteres especiais e divide palavras compostas para garantir precis√£o na frequ√™ncia de palavras.

  - **M√©todo [`void Document::addWord(const std::string &word)`](src/document.cpp)**: 
    1. Adiciona uma palavra ao documento. 
    2. Se `OPTIMIZE` estiver ativado, armazena em `wordsFreq` (unordered_map); caso contr√°rio, em `docWords` (list).

  - **M√©todo [`std::string normalize(const std::string &word)`](src/document.cpp)**: Normaliza uma palavra, convertendo caracteres acentuados em equivalentes sem acento e convertendo para min√∫sculas.

  - **M√©todo [`void Document::imprimindoPalavras()`](src/document.cpp)**: Imprime todas as palavras e suas frequ√™ncias no console, de acordo com o modo de otimiza√ß√£o (`OPTIMIZE`).

  #### Arquivo [ranking.cpp](src/ranking.cpp)

  Arquivo que cont√©m a implementa√ß√£o dos m√©todos da classe `Ranking`, respons√°vel por ler as frases a serem buscadas, armazenar as stopwords e calcular o fator TF/IDF de cada documento para cada termo e ranque√°-los em ordem decrescente.

  - **Construtor [`Ranking(std::string phrase)`](src/ranking.cpp)**: Construtor que inicializa `documents` com base nos arquivos em `filenames`, l√™ palavras de parada e processa a frase de busca.

  - **M√©todo [`void Ranking::readStopWords()`](src/ranking.cpp)**: L√™ o arquivo de stopwords e insere cada palavra, normalizada, em `stopWords`.

  - **M√©todo [`void Ranking::readPhrase(const std::string &phrase)`](src/ranking.cpp)**: Processa a frase de busca, removendo caracteres especiais, normalizando as palavras e ignorando palavras de parada.

  - **M√©todo [`double Ranking::calculateIDF(const std::string &term)`](src/ranking.cpp)**: Calcula o IDF de uma palavra, com base na propor√ß√£o de documentos que a cont√™m.

  - **M√©todo [`double Ranking::calculateTFIDF(const std::string &term, Document doc)`](src/ranking.cpp)**: Calcula o valor TF-IDF de uma palavra espec√≠fica em um documento, multiplicando o TF pelo IDF.

  - **M√©todo [`void Ranking::calculateRelevanceDoc()`](src/ranking.cpp)**: Para cada documento, calcula a relev√¢ncia com base nas palavras da frase de busca.

  - **M√©todo [`void Ranking::quickSort(std::list<Document> &documents, int left, int right)`](src/ranking.cpp)**: Implementa√ß√£o do QuickSort para ordenar a lista de documentos de acordo com sua relev√¢ncia.

  - **M√©todo [`int Ranking::partition(std::list<Document> &documents, int left, int right)`](src/ranking.cpp)**: Particiona o vetor de documentos em duas partes e ordena-os de acordo com a relev√¢ncia.  
  
<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>


## üìä Testes e Resultados

<div align="justify">

Para avaliar a efic√°√™ncia do algoritmo de ranqueamento de documentos, foram realizados testes com diferentes frases de busca e documentos. Vamos observar a diferen√ßa de desempenho entre as duas estruturas de dados utilizadas, a lista encadeada e a Hash Table, e analisar a precis√£o dos resultados obtidos.

### Configura√ß√£o dos Testes

Os testes foram realizados com diferentes frases de busca e documentos. As frases de busca foram escolhidas aleatoriamente e os documentos utilizados foram trechos de livros e relatos hist√≥ricos. Os documentos foram escolhidos para conter termos comuns e raros, a fim de avaliar a efic√°cia do algoritmo em diferentes cen√°rios. 

  - **Documentos**: 6 documentos de diferentes tamanhos, contendo textos de dom√≠nios variados.
    - [doc1.txt](datasets/doc1.txt): "A M√£o e A Luva", de Machado de Assis.
    - [doc2.txt](datasets/doc2.txt): A B√≠blia Sagrada.
    - [doc3.txt](datasets/doc3.txt): "Dom Casmurro", de Machado de Assis.
    - [doc4.txt](datasets/doc4.txt): "Quincas Borba", de Machado de Assis.
    - [doc5.txt](datasets/doc5.txt): "A Semana", de Machado de Assis.
    - [doc6.txt](datasets/doc6.txt): "Rela√ß√£o do formidavel, e lastimoso terremoto succedido no Reino de Valen√ßa".
  - **Frases de Buscas**: 7 frases de busca, contendo termos de diferentes frequ√™ncias e relev√¢ncias.
    - *"A Quincas Borba"*: resultado esperado √© o documento "Quincas Borba".
    - *"Senhor Jesus Cristo"*: resultado esperado √© o documento "A B√≠blia Sagrada".
    - *"Reino de Valen√ßa"*: resultado esperado √© o documento "Rela√ß√£o do formidavel, e lastimoso terremoto succedido no Reino de Valen√ßa".
    - *"hoje o dia est√° nublado"*: frase aleat√≥ria, sem correspond√™ncia com os documentos.
    - *"Rubi√£o fitava a enseada,--eram oito horas da manh√£"*: trecho do livro "Quincas Borba".
    - *"O terremoto no Reino de Valen√ßa foi uma trag√©dia que marcou a hist√≥ria, deixando um rastro de destrui√ß√£o e desespero"*: frase com termos espec√≠ficos presentes um pouco em cada documento.
    - *"grinaldas alcovas Nero aut√≥psias"*: palavras diferentes encontradas cada uma em um documento diferente.
  - **Stopwords**: 1 arquivo contendo stopwords da l√≠ngua portuguesa, este arquivo foi disponibilizado pelo professor contendo 264 palavras ([stopwords.txt](datasets/stopwords.txt))
  - **Otimiza√ß√£o**: A otimiza√ß√£o foi feita por meio de um par√¢metro de configura√ß√£o, `#define OPTIMIZE 1`, que define a estrutura de dados a ser utilizada. Se `OPTIMIZE` for 1, a estrutura de dados utilizada ser√° a Hash Table. Se `OPTIMIZE` for 0, a estrutura de dados utilizada ser√° a lista encadeada.

### Execu√ß√£o

Os resultados dos testes foram avaliados com base na precis√£o e no desempenho do algoritmo. A precis√£o foi avaliada comparando os resultados obtidos com os resultados esperados. O desempenho foi avaliado com base no tempo de execu√ß√£o do algoritmo, medido em milissegundos. Os resultados dos testes foram comparados entre a lista encadeada e a Hash Table para avaliar a efic√°cia de cada estrutura de dados.

- **1¬∞ Execu√ß√£o**: Execu√ß√£o sem utilizar a otimiza√ß√£o: 

</div> 

<div align='center'>
  <img src='./images/execucaoLista.png' alt='Execu√ß√£o sem Otimiza√ß√£o' width='800px'>   
  <p>Figura 1: Resultados da execu√ß√£o sem otimiza√ß√£o.</p>
</div>

- **2¬∞ Execu√ß√£o**: Execu√ß√£o utilizando a otimiza√ß√£o:

<div align='center'>
  <img src='./images/execucaoHash.png' alt='Execu√ß√£o com Otimiza√ß√£o' width='800px'>   
  <p>Figura 2: Resultados da execu√ß√£o com otimiza√ß√£o.</p>
</div>

### Testes de Precis√£o

<div align="justify">

Por meio da l√≥gica de ranqueamento com o algoritmo **TF-IDF**, o sistema conseguiu priorizar documentos relevantes com base nos termos buscados. Isso foi verificado ao observar que, para consultas como *"A Quincas Borba"*, o sistema ranqueou o documento [`doc4.txt`](datasets/doc4.txt), que corresponde ao livro "Quincas Borba" de Machado de Assis, como o mais relevante. O mesmo padr√£o foi observado nas demais buscas, como *"Senhor Jesus Cristo"* e *"Reino de Valen√ßa"*, onde os documentos mais relevantes foram ranqueados no topo, demonstrando precis√£o na identifica√ß√£o dos documentos de acordo com a relev√¢ncia dos termos.

Para frases aleat√≥rias, como *"hoje o dia est√° nublado"*, que n√£o t√™m correspond√™ncia clara com nenhum documento, o sistema ainda retornou relev√¢ncias pr√≥ximas de zero, indicando que a estrutura de ranqueamento √© eficiente em discriminar termos irrelevantes ou que n√£o est√£o presentes nos documentos.

Esses resultados destacam a capacidade do algoritmo de lidar com palavras comuns e raras de forma eficiente, mostrando que o ranqueamento considera a frequ√™ncia e a import√¢ncia dos termos em cada contexto.

### Testes de Desempenho

Para avaliar o desempenho do algoritmo **TF-IDF**, utilizamos duas estruturas de dados diferentes: a Hash Table implementada com [`unordered_map`](https://www.cplusplus.com/reference/unordered_map/) e a lista encadeada implementada com [`std::list`](https://www.cplusplus.com/reference/list/list/). Cada uma dessas estruturas foi escolhida para armazenar e gerenciar a frequ√™ncia de palavras nos documentos durante o processo de ranqueamento.

  - **COMPORTAMENTO ESTRUTURAL:**
    - **Lista Encadeada (`std::list`):** A [`std::list`](https://www.cplusplus.com/reference/list/list/) √© uma estrutura de dados que permite inser√ß√µes e remo√ß√µes eficientes em qualquer posi√ß√£o, mas possui uma desvantagem significativa em opera√ß√µes de busca. Como uma lista duplamente encadeada, [`std::list`](https://www.cplusplus.com/reference/list/list/) n√£o possui acesso direto aos elementos e, para localizar a frequ√™ncia de uma palavra, √© necess√°rio percorrer todos os elementos at√© encontrar o termo desejado. Em termos de complexidade, a busca em uma lista encadeada tem custo $O(n)$, onde $n$ √© o n√∫mero de palavras na lista. Isso torna a [`std::list`](https://www.cplusplus.com/reference/list/list/) menos eficiente quando √© necess√°rio realizar buscas r√°pidas e repetitivas, como no c√°lculo de **TF-IDF** para m√∫ltiplos termos em diferentes documentos.

    - **Hash Table (`unordered_map`):** O [`unordered_map`](https://www.cplusplus.com/reference/unordered_map/) √© uma estrutura de dados implementada em C++ que utiliza uma fun√ß√£o de hash para mapear chaves (neste caso, palavras) diretamente para suas frequ√™ncias. Isso permite uma busca em tempo constante $O(1)$ na maioria dos casos, j√° que o mapeamento direto evita a necessidade de percorrer a estrutura inteira. Em um contexto de ranqueamento de documentos, onde cada busca pode envolver m√∫ltiplos termos, essa efici√™ncia na busca torna o [`unordered_map`](https://www.cplusplus.com/reference/unordered_map/) a estrutura ideal, especialmente ao lidar com termos raros e espec√≠ficos que possuem alta relev√¢ncia no algoritmo **TF-IDF**.

### Resultados e An√°lise

Abaixo est√£o os tempos de execu√ß√£o obtidos para cada estrutura de dados:
  - *SEM OTIMIZA√á√ÉO (`std::list`):* **4 minutos, 10 segundos e 742 milissegundos.**
  - *COM OTIMIZA√á√ÉO (`unordered_map`):* **16 segundos e 100 milissegundos.**

Esses resultados mostram que o uso do [`unordered_map`](https://www.cplusplus.com/reference/unordered_map/) proporciona uma melhoria significativa no desempenho do sistema, reduzindo drasticamente o tempo de execu√ß√£o. Essa diferen√ßa √© especialmente evidente em buscas com termos espec√≠ficos e menos frequentes, que s√£o fundamentais para o c√°lculo do IDF (Inverso da Frequ√™ncia de Documento) no **TF-IDF**. Ao buscar por termos raros, como *"Reino de Valen√ßa"*, o [`unordered_map`](https://www.cplusplus.com/reference/unordered_map/) permite acessar rapidamente as frequ√™ncias de *"Reino"* e *"Valen√ßa"* em cada documento, sem precisar iterar por todos os termos. Em contraste, uma busca com [`std::list`](https://www.cplusplus.com/reference/list/list/) exigiria percorrer toda a lista para cada termo, aumentando significativamente o tempo de processamento.

**Vantagens do Uso de [`unordered_map`](https://www.cplusplus.com/reference/unordered_map/) no Algoritmo TF-IDF**

A escolha pelo [`unordered_map`](https://www.cplusplus.com/reference/unordered_map/) oferece v√°rias vantagens espec√≠ficas para o algoritmo **TF-IDF**:

  - *Acesso R√°pido a Termos Espec√≠ficos:* Como cada termo √© mapeado diretamente para um √≠ndice, o [`unordered_map`](https://www.cplusplus.com/reference/unordered_map/) permite acessar a frequ√™ncia de qualquer termo instantaneamente. Isso √© particularmente √∫til ao ranquear documentos onde termos raros t√™m mais peso, pois o **TF-IDF** atribui uma relev√¢ncia maior a termos menos frequentes.

  - *Escalabilidade:* Em cen√°rios com grandes volumes de dados ou documentos extensos, o tempo de execu√ß√£o usando [`unordered_map`](https://www.cplusplus.com/reference/unordered_map/) permanece quase constante para buscas, tornando-o mais escal√°vel em compara√ß√£o √† [`std::list`](https://www.cplusplus.com/reference/list/list/).

  - *Efici√™ncia no Ranqueamento de Documentos:* Como o ranqueamento envolve m√∫ltiplas buscas de termos em cada documento, a efici√™ncia do [`unordered_map`](https://www.cplusplus.com/reference/unordered_map/) em opera√ß√µes de busca resulta em uma experi√™ncia de processamento muito mais r√°pida, especialmente ao comparar o desempenho em um conjunto de documentos grandes e termos raros.

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## An√°lise Hipot√©tica: Uso de √Årvores/Grafos para Ranqueamento de Documentos

<div align="justify">

Al√©m do **TF-IDF**, que se baseia em estat√≠sticas de frequ√™ncia de termos para ranquear documentos, outra abordagem comum em recupera√ß√£o de informa√ß√£o √© o uso de estruturas de dados hier√°rquicas, como `√°rvores` e `grafos`. Essas estruturas podem ser usadas para representar rela√ß√µes entre documentos e termos de forma a capturar conex√µes e similaridades entre os documentos de forma mais complexa e sem√¢ntica. Com base nos estudo feitos sobre √°rvores e grafos para este projeto ([^2], [^3], [^4], [^5]), podemos considerar algumas abordagens hipot√©ticas para o ranqueamento de documentos:

### Estruturas de √Årvores para Ranqueamento


  - **√Årvores de Decis√£o:** Uma √°rvore de decis√£o poderia ser utilizada para ranquear documentos em rela√ß√£o a uma consulta, onde cada n√≥ da √°rvore representa uma decis√£o baseada em um termo ou conjunto de termos. Ao navegar na √°rvore, o sistema poderia "filtrar" documentos com base em termos relevantes para a consulta, terminando em folhas que cont√™m os documentos mais relevantes. Essa abordagem permite uma navega√ß√£o direcionada, reduzindo o n√∫mero de documentos a serem ranqueados a partir de uma divis√£o hier√°rquica.

  - **√Årvores de Sufixos:** Outra alternativa seria o uso de √°rvores de sufixos, que s√£o eficientes para buscas r√°pidas de substrings em grandes cole√ß√µes de texto. Ao utilizar uma √°rvore de sufixos, cada termo de busca poderia ser rapidamente localizado, identificando os documentos que cont√™m os termos exatos ou varia√ß√µes desses termos. Essa estrutura permite que buscas de frases exatas sejam realizadas em tempo linear, o que poderia ser vantajoso em consultas espec√≠ficas ou quando se deseja encontrar correspond√™ncias exatas.

### Uso de Grafos para Capturar Rela√ß√µes entre Termos e Documentos

O uso de grafos representa uma abordagem mais avan√ßada para ranqueamento, capturando n√£o apenas a presen√ßa ou aus√™ncia de termos, mas tamb√©m as rela√ß√µes entre os documentos:

  - **Grafos de Similaridade:** Em um grafo de similaridade, cada n√≥ representa um documento, e arestas s√£o criadas entre documentos com base em similaridades (por exemplo, documentos que compartilham um alto n√∫mero de termos ou t√≥picos em comum). Utilizando algoritmos de an√°lise de grafos, como PageRank ou HITS, seria poss√≠vel identificar documentos centrais na rede de documentos. Essas centralidades podem indicar documentos que s√£o mais relevantes ou influentes em um determinado t√≥pico, melhorando o ranqueamento com base em contextos mais amplos.

  - **Modelos de Redes Sem√¢nticas:** Outra abordagem com grafos envolve a cria√ß√£o de redes sem√¢nticas onde termos e documentos s√£o representados como n√≥s. As arestas indicam a rela√ß√£o sem√¢ntica entre termos ou entre termos e documentos, capturando n√£o apenas frequ√™ncias de palavras, mas tamb√©m o significado e o contexto dos termos. Em literaturas mais modernas de recupera√ß√£o de informa√ß√£o, modelos como esses s√£o utilizados em Word Embeddings e Grafo de Conhecimento para ranquear documentos de maneira mais precisa, considerando contextos sem√¢nticos al√©m de apenas frequ√™ncias de palavras.

### Compara√ß√£o com o **TF-IDF**

Embora o **TF-IDF** seja um m√©todo eficaz para ranquear documentos em termos de frequ√™ncia de palavras e inverta a relev√¢ncia baseada na raridade dos termos, ele n√£o captura relacionamentos complexos ou sem√¢nticos entre os documentos. O uso de √°rvores e grafos, por outro lado, permite:

  - **Modelagem de Relacionamentos entre Documentos:** Grafos, por exemplo, podem modelar similaridades e rela√ß√µes entre documentos com uma profundidade que o **TF-IDF** n√£o oferece. Isso √© especialmente √∫til em cole√ß√µes de documentos onde o contexto √© importante, pois essas estruturas permitem identificar documentos que s√£o sem√¢ntica ou contextualmente pr√≥ximos entre si.

  - **Escalabilidade com Navega√ß√£o Estruturada:** Estruturas de √°rvore, como √°rvores de decis√£o ou de sufixos, permitem uma divis√£o estruturada dos documentos, otimizando a navega√ß√£o em grandes volumes de dados, enquanto o **TF-IDF** trata cada termo de forma independente e linear.

  - **An√°lise Sem√¢ntica:** Enquanto o **TF-IDF** se limita a uma an√°lise estat√≠stica, grafos e √°rvores permitem uma an√°lise sem√¢ntica mais complexa, capturando significados e contextos, o que pode levar a um ranqueamento mais preciso em consultas que envolvem termos amb√≠guos ou contextos espec√≠ficos.

Portanto, o uso de √°rvores e grafos no ranqueamento de documentos proporciona um n√≠vel de sofistica√ß√£o superior ao **TF-IDF**, especialmente quando se lida com documentos inter-relacionados ou com a necessidade de entender conex√µes sem√¢nticas entre termos. No entanto, essas estruturas tamb√©m t√™m um custo computacional maior e complexidade de implementa√ß√£o que devem ser considerados. Em contextos de sistemas de busca onde a precis√£o sem√¢ntica e a rela√ß√£o entre documentos s√£o cr√≠ticas, √°rvores e grafos oferecem uma abordagem mais robusta, sendo amplamente discutidos e implementados na literatura de Recupera√ß√£o de Informa√ß√£o e Processamento de Linguagem Natural.

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>


## üèÅ Conclus√£o

<div  align="justify">

Para concluir, o projeto demonstrou a efici√™ncia e a precis√£o do algoritmo **TF-IDF** na tarefa de ranqueamento de documentos, utilizando frequ√™ncias de termos e invers√£o de frequ√™ncia para calcular a relev√¢ncia de cada documento em rela√ß√£o a uma consulta espec√≠fica. A implementa√ß√£o em C++ com *Hash Table* e *lista encadeada* possibilitou uma an√°lise comparativa do desempenho dessas estruturas, mostrando uma melhoria significativa em tempo de execu√ß√£o com o uso da *Hash Table*. Esse ganho de efici√™ncia confirma a import√¢ncia de selecionar estruturas de dados adequadas ao contexto da aplica√ß√£o.

Al√©m disso, os testes realizados indicaram que o **TF-IDF** foi bem-sucedido em ranquear documentos relevantes para termos espec√≠ficos, revelando a capacidade do algoritmo em identificar palavras-chave com precis√£o. Observou-se, tamb√©m, que para frases irrelevantes ou que n√£o continham correspond√™ncia direta com os documentos, o sistema respondeu adequadamente, atribuindo baixa relev√¢ncia a esses documentos. Isso demonstrou a robustez do algoritmo na discrimina√ß√£o de termos que impactam diretamente a relev√¢ncia do conte√∫do. Outra observa√ß√£o importante foi a acur√°cia do algoritmo ao lidar com senten√ßas completas de um documento. Nesse caso, mesmo que a frase seja exatamente uma que aparece no documento, n√£o garante que ele ser√° ranqueado como o mais relevante. Isso ocorre porque o algoritmo n√£o leva em considera√ß√£o a ordem das palavras, apenas a frequ√™ncia de cada termo no documento por completo.

Por fim, este trabalho tamb√©m refletiu sobre o uso potencial de estruturas de dados alternativas, como √°rvores e grafos, que poderiam capturar rela√ß√µes sem√¢nticas e contextuais mais complexas entre documentos. Embora o **TF-IDF** seja eficaz e adequado para este tipo de ranqueamento, explorar grafos e √°rvores em projetos futuros poder√° enriquecer a an√°lise sem√¢ntica, especialmente em contextos onde h√° interconex√µes entre os documentos.
  
</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üî® Come√ßando

<div align="justify">

  Nesta se√ß√£o est√£o exemplificados os meios atrav√©s dos quais se tornam poss√≠veis a compila√ß√£o e execu√ß√£o do programa apresentado.

</div>

### Pr√©-requisitos

<div align="justify">

  Inicialmente, algumas considera√ß√µes importantes sobre como se deve preparar o ambiente para compilar e executar o programa:

</div>

> [!NOTE]
> Recomenda-se usar uma distribui√ß√£o de sistema operacional Linux ou o Windows Subsystem for Linux (WSL), pois os comandos no [makefile][makefile] foram selecionados para funcionar em um ambiente [shell/bash][bash-url].

<div align="justify">

  Considerando um ambiente shell, garanta que os seguintes comandos j√° foram executados:
  - Atualize os pacotes antes da instala√ß√£o dos compiladores:
  console
  sudo apt update
  
  - Instale a cole√ß√£o de compiladores __GNU/g++_ e o _make__:
  console
  sudo apt install build-essential
  
  - Se necess√°rio, instale o __make__ individualmente:
  console
  sudo apt install make
  

</div>

### Instalando

<div align="justify">
  Com o ambiente preparado, os seguintes passos s√£o para a instala√ß√£o, compila√ß√£o e execu√ß√£o do programa localmente:

  1. Clone o reposit√≥rio no diret√≥rio desejado:
  console
  git clone https://github.com/dudatsouza/tf-idf.git
  cd tf-idf
  
  2. Compile o programa com o __make__, o que gera a pasta build, que cont√©m arquivos de objeto e um arquivo execut√°vel:
  console
  make
  
  3. Execute o programa da pasta build ap√≥s a compila√ß√£o:
  console
  make run
  

  4. Se necess√°rio, apague a √∫ltima compila√ß√£o da pasta build:
  console
  make clean
  

  O programa estar√° pronto para ser testado. Veja a tabela abaixo com alguns comandos do makefile:

</div>

<div align="center">

  | Comando      | *Descri√ß√£o*                           |
  |--------------|-----------------------------------------|
  | make       | Compila o programa.                     |
  | make run   | Executa o programa com o arquivo de entrada fornecido. |
  | make clean | Remove os arquivos compilados.          |

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üß™ Ambiente de Compila√ß√£o e Execu√ß√£o

<div align="justify">

  O trabalho foi desenvolvido e testado em v√°rias configura√ß√µes de hardware. Podemos destacar algumas configura√ß√µes de Sistema Operacional e Compilador, pois as demais configura√ß√µes n√£o influenciam diretamente no desempenho do programa.

</div>

<div align='center'>

![Ubuntu][ubuntu-badge]
![GCC][gcc-badge]
![Make][make-badge] 

| *Hardware* | *Especifica√ß√µes* |
|:------------:|:-------------------:|
| *Laptop*   | Dell Inspiron 13 5330 |
| *Processador* | Intel Core i7-1360P |
| *Mem√≥ria RAM* | 16 GB DDR5 |
| *Sistema Operacional* | Windows 11 |
| *IDE* | Visual Studio Code |
| *Placa de V√≠deo* | Intel Iris Xe Graphics |

</div>

> [!IMPORTANT] 
> Para que os testes tenham validade, considere as especifica√ß√µes
> do ambiente de compila√ß√£o e execu√ß√£o do programa.

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üì® Contato

<div align="center">
  <br><br>
     <i>Guilherme Alvarenga de Azevedo - Graduando - 4¬∫ Per√≠odo de Engenharia de Computa√ß√£o @ CEFET-MG</i>
  <br><br>
  
  [![Gmail][gmail-badge]][gmail-autor1]
  [![Linkedin][linkedin-badge]][linkedin-autor1]
  [![Telegram][telegram-badge]][telegram-autor1]
  
  
  <br><br>
     <i>Maria Eduarda Teixeira Souza - Graduando - 4¬∫ Per√≠odo de Engenharia de Computa√ß√£o @ CEFET-MG</i>
  <br><br>
  
  [![Gmail][gmail-badge]][gmail-autor2]
  [![Linkedin][linkedin-badge]][linkedin-autor2]
  [![Telegram][telegram-badge]][telegram-autor2]
  
  <br><br>
     <i>Matheus Emanuel da Silva - Graduando - 4¬∫ Per√≠odo de Engenharia de Computa√ß√£o @ CEFET-MG</i>
  <br><br>
  
  [![Gmail][gmail-badge]][gmail-autor3]
  [![Linkedin][linkedin-badge]][linkedin-autor3]
  [![Telegram][telegram-badge]][telegram-autor3]

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

<a name="referencias">üìö Refer√™ncias</a>

[^1]: Sp√§rck Jones, K. (1972). A statistical interpretation of term specificity and its application in retrieval. Journal of Documentation, 28(1), 11-21. (https://www.staff.city.ac.uk/~sbrp622/idfpapers/ksj_orig.pdf)

[^2]: Philip L.H. Yu, Wai Ming Wan, and Paul H. Lee. Decision Tree Modeling for Ranking Data. (https://www.researchgate.net/publication/252998138_Decision_Tree_Modeling_for_Ranking_Data)

[^3]: Ming Zhong, Mengchi Liu. Ranking the answer trees of graph search by both structure and content. (https://dl.acm.org/doi/abs/10.1145/2379307.2379314)

[^4]: Claudio Lucchese, Franco Maria Nardini, salvatore Orlando, Raffaele Perego, Nicola Tonellotto, Rossano Venturini. QuickScorer: a Fast Algorithm to Rank Documents with
Additive Ensembles of Regression Trees. (https://iris.unive.it/bitstream/10278/3661259/7/paper.pdf)

[^5]: Rada Mihalcea. Graph-based Ranking Algorithms for Sentence Extraction, Applied to Text Summarization. (https://dl.acm.org/doi/pdf/10.3115/1219044.1219064)






[vscode-badge]: https://img.shields.io/badge/Visual%20Studio%20Code-0078d7.svg?style=for-the-badge&logo=visual-studio-code&logoColor=white
[vscode-url]: https://code.visualstudio.com/docs/?dv=linux64_deb
[make-badge]: https://img.shields.io/badge/_-MAKEFILE-427819.svg?style=for-the-badge
[make-url]: https://www.gnu.org/software/make/manual/make.html
[cpp-badge]: https://img.shields.io/badge/c++-%2300599C.svg?style=for-the-badge&logo=c%2B%2B&logoColor=white
[cpp-url]: https://en.cppreference.com/w/cpp
[trabalho-url]: https://drive.google.com/file/d/1-IHbGaA1BIC6_CMBydOC-NbV2bCERc8r/view?usp=sharing
[github-prof]: https://github.com/mpiress
[main-ref]: src/main.cpp
[branchAMM-url]: https://github.com/alvarengazv/trabalhosAEDS1/tree/AlgoritmosMinMax
[makefile]: ./makefile
[bash-url]: https://www.hostgator.com.br/blog/o-que-e-bash/
[lenovo-badge]: https://img.shields.io/badge/lenovo%20laptop-E2231A?style=for-the-badge&logo=lenovo&logoColor=white
[ubuntu-badge]: https://img.shields.io/badge/Ubuntu-E95420?style=for-the-badge&logo=ubuntu&logoColor=white
[Ubuntu-url]: https://ubuntu.com/
[ryzen5500-badge]: https://img.shields.io/badge/AMD%20Ryzen_5_5500U-ED1C24?style=for-the-badge&logo=amd&logoColor=white
[ryzen3500-badge]: https://img.shields.io/badge/AMD%20Ryzen_5_3500X-ED1C24?style=for-the-badge&logo=amd&logoColor=white
[windows-badge]: https://img.shields.io/badge/Windows-0078D6?style=for-the-badge&logo=windows&logoColor=white
[gcc-badge]: https://img.shields.io/badge/GCC-5C6EB8?style=for-the-badge&logo=gnu&logoColor=white


[linkedin-autor1]: https://www.linkedin.com/in/guilherme-alvarenga-de-azevedo-959474201/
[telegram-autor1]: https://t.me/alvarengazv
[gmail-autor1]: mailto:gui.alvarengas234@gmail.com

[linkedin-autor2]: https://www.linkedin.com/in/dudatsouza/
[telegram-autor2]: https://t.me/dudat_18
[gmail-autor2]: mailto:dudateixeirasouza@gmail.com

[linkedin-autor3]: https://www.linkedin.com/
[telegram-autor3]: https://t.me/
[gmail-autor3]: mailto:memanuel643@gmail.com

[linkedin-badge]: https://img.shields.io/badge/-LinkedIn-0077B5?style=for-the-badge&logo=Linkedin&logoColor=white
[telegram-badge]: https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&logo=telegram&logoColor=white
[gmail-badge]: https://img.shields.io/badge/-Gmail-D14836?style=for-the-badge&logo=Gmail&logoColor=white